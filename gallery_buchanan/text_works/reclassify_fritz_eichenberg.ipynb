{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to reclassify prints into prints, posters, and maybe artists books\n",
    "\n",
    "Import libraries and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "def csv_read(path: str, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Loads a CSV table into a Pandas DataFrame with all cells as strings and blank cells as empty strings\n",
    "    \n",
    "    Keyword argument:\n",
    "    rows -- the number of rows of the table to return when used for testing. When omitted, all rows are returned.\n",
    "    \"\"\"\n",
    "    dataframe = pd.read_csv(path, na_filter=False, dtype = str)\n",
    "    if 'rows' in kwargs:\n",
    "        return dataframe.head(kwargs['rows']).copy(deep=True)\n",
    "    else:\n",
    "        return dataframe\n",
    "\n",
    "class Sparqler:\n",
    "    \"\"\"Build SPARQL queries of various sorts\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    method: str\n",
    "        Possible values are \"post\" (default) or \"get\". Use \"get\" if read-only query endpoint.\n",
    "        Must be \"post\" for update endpoint.\n",
    "    endpoint: URL\n",
    "        Defaults to Wikidata Query Service if not provided.\n",
    "    useragent : str\n",
    "        Required if using the Wikidata Query Service, otherwise optional.\n",
    "        Use the form: appname/v.v (URL; mailto:email@domain.com)\n",
    "        See https://meta.wikimedia.org/wiki/User-Agent_policy\n",
    "    session: requests.Session\n",
    "        If provided, the session will be used for all queries. Note: required for the Commons Query Service.\n",
    "        If not provided, a generic requests method (get or post) will be used.\n",
    "        NOTE: Currently only implemented for the .query() method since I don't have any way to test the mehtods that write.\n",
    "    sleep: float\n",
    "        Number of seconds to wait between queries. Defaults to 0.1\n",
    "        \n",
    "    Required modules:\n",
    "    -------------\n",
    "    requests, datetime, time\n",
    "    \"\"\"\n",
    "    def __init__(self, method='post', endpoint='https://query.wikidata.org/sparql', useragent=None, session=None, sleep=0.1):\n",
    "        # attributes for all methods\n",
    "        self.http_method = method\n",
    "        self.endpoint = endpoint\n",
    "        if useragent is None:\n",
    "            if self.endpoint == 'https://query.wikidata.org/sparql':\n",
    "                print('You must provide a value for the useragent argument when using the Wikidata Query Service.')\n",
    "                print()\n",
    "                raise KeyboardInterrupt # Use keyboard interrupt instead of sys.exit() because it works in Jupyter notebooks\n",
    "        self.session = session\n",
    "        self.sleep = sleep\n",
    "\n",
    "        self.requestheader = {}\n",
    "        if useragent:\n",
    "            self.requestheader['User-Agent'] = useragent\n",
    "        \n",
    "        if self.http_method == 'post':\n",
    "            self.requestheader['Content-Type'] = 'application/x-www-form-urlencoded'\n",
    "\n",
    "    def query(self, query_string, form='select', verbose=False, **kwargs):\n",
    "        \"\"\"Sends a SPARQL query to the endpoint.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        form : str\n",
    "            The SPARQL query form.\n",
    "            Possible values are: \"select\" (default), \"ask\", \"construct\", and \"describe\".\n",
    "        mediatype: str\n",
    "            The response media type (MIME type) of the query results.\n",
    "            Some possible values for \"select\" and \"ask\" are: \"application/sparql-results+json\" (default) and \"application/sparql-results+xml\".\n",
    "            Some possible values for \"construct\" and \"describe\" are: \"text/turtle\" (default) and \"application/rdf+xml\".\n",
    "            See https://docs.aws.amazon.com/neptune/latest/userguide/sparql-media-type-support.html#sparql-serialization-formats-neptune-output\n",
    "            for response serializations supported by Neptune.\n",
    "        verbose: bool\n",
    "            Prints status when True. Defaults to False.\n",
    "        default: list of str\n",
    "            The graphs to be merged to form the default graph. List items must be URIs in string form.\n",
    "            If omitted, no graphs will be specified and default graph composition will be controlled by FROM clauses\n",
    "            in the query itself. \n",
    "            See https://www.w3.org/TR/sparql11-query/#namedGraphs and https://www.w3.org/TR/sparql11-protocol/#dataset\n",
    "            for details.\n",
    "        named: list of str\n",
    "            Graphs that may be specified by IRI in a query. List items must be URIs in string form.\n",
    "            If omitted, named graphs will be specified by FROM NAMED clauses in the query itself.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        If the form is \"select\" and mediatype is \"application/json\", a list of dictionaries containing the data.\n",
    "        If the form is \"ask\" and mediatype is \"application/json\", a boolean is returned.\n",
    "        If the mediatype is \"application/json\" and an error occurs, None is returned.\n",
    "        For other forms and mediatypes, the raw output is returned.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        To get UTF-8 text in the SPARQL queries to work properly, send URL-encoded text rather than raw text.\n",
    "        That is done automatically by the requests module for GET. I guess it also does it for POST when the\n",
    "        data are sent as a dict with the urlencoded header. \n",
    "        See SPARQL 1.1 protocol notes at https://www.w3.org/TR/sparql11-protocol/#query-operation        \n",
    "        \"\"\"\n",
    "        query_form = form\n",
    "        if 'mediatype' in kwargs:\n",
    "            media_type = kwargs['mediatype']\n",
    "        else:\n",
    "            if query_form == 'construct' or query_form == 'describe':\n",
    "            #if query_form == 'construct':\n",
    "                media_type = 'text/turtle'\n",
    "            else:\n",
    "                media_type = 'application/sparql-results+json' # default for SELECT and ASK query forms\n",
    "        self.requestheader['Accept'] = media_type\n",
    "            \n",
    "        # Build the payload dictionary (query and graph data) to be sent to the endpoint\n",
    "        payload = {'query' : query_string}\n",
    "        if 'default' in kwargs:\n",
    "            payload['default-graph-uri'] = kwargs['default']\n",
    "        \n",
    "        if 'named' in kwargs:\n",
    "            payload['named-graph-uri'] = kwargs['named']\n",
    "\n",
    "        if verbose:\n",
    "            print('querying SPARQL endpoint')\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "        if self.http_method == 'post':\n",
    "            if self.session is None:\n",
    "                response = requests.post(self.endpoint, data=payload, headers=self.requestheader)\n",
    "            else:\n",
    "                response = self.session.post(self.endpoint, data=payload, headers=self.requestheader)\n",
    "        else:\n",
    "            if self.session is None:\n",
    "                response = requests.get(self.endpoint, params=payload, headers=self.requestheader)\n",
    "            else:\n",
    "                response = self.session.get(self.endpoint, params=payload, headers=self.requestheader)\n",
    "        elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "        self.response = response.text\n",
    "        time.sleep(self.sleep) # Throttle as a courtesy to avoid hitting the endpoint too fast.\n",
    "\n",
    "        if verbose:\n",
    "            print('done retrieving data in', int(elapsed_time), 's')\n",
    "\n",
    "        if query_form == 'construct' or query_form == 'describe':\n",
    "            return response.text\n",
    "        else:\n",
    "            if media_type != 'application/sparql-results+json':\n",
    "                return response.text\n",
    "            else:\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                except:\n",
    "                    return None # Returns no value if an error. \n",
    "\n",
    "                if query_form == 'select':\n",
    "                    # Extract the values from the response JSON\n",
    "                    results = data['results']['bindings']\n",
    "                else:\n",
    "                    results = data['boolean'] # True or False result from ASK query \n",
    "                return results           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"\"\"select distinct ?qid ?statementIri where {\n",
    "  ?qid wdt:P195 wd:Q18563658.\n",
    "  ?qid wdt:P170 wd:Q2605345.\n",
    "  ?qid wdt:P31 wd:Q478798.\n",
    "  ?qid p:P31 ?statementIri.\n",
    "  }\"\"\"\n",
    "\n",
    "user_agent = 'TestAgent/0.1 (mailto:steve.baskauf@vanderbilt.edu)'\n",
    "wdqs = Sparqler(useragent=user_agent)\n",
    "data = wdqs.query(query_string)\n",
    "\n",
    "#print(json.dumps(data, indent=2))\n",
    "\n",
    "# Create a dictionary of the Q numbers and statement UUIDs\n",
    "statement_dict = {}\n",
    "\n",
    "# Create a list of the Q numbers\n",
    "qid_list = []\n",
    "\n",
    "for item in data:\n",
    "    # extract the Q number from the item's URI\n",
    "    qid = item['qid']['value'].replace('http://www.wikidata.org/entity/', '')\n",
    "\n",
    "    # extract the statement UUID from the statement IRI\n",
    "    statement_iri = item['statementIri']['value']\n",
    "    statement_id = statement_iri.replace('http://www.wikidata.org/entity/statement/', '')\n",
    "    # remove the Q number from the statement UUID before the first dash\n",
    "    pieces = statement_id.split('-')[1:]\n",
    "    statement_id = '-'.join(pieces)\n",
    "    statement_dict[qid] = statement_id\n",
    "    qid_list.append(qid)\n",
    "\n",
    "print(qid_list)\n",
    "print(statement_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing metadata. inventory_number is the same as accession_number.\n",
    "path_to_vanderbot_metadata = '../../gallery_works/works_multiprop.csv'\n",
    "vanderbot_metadata = csv_read(path_to_vanderbot_metadata)\n",
    "\n",
    "# Set the index to the Q ID, but leave the Q ID as a column\n",
    "vanderbot_metadata = vanderbot_metadata.set_index('qid', drop=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the instance_of_uuid identifiers for the prints that need to be reclassified so that they can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty string to hold the error messages\n",
    "error_messages = ''\n",
    "\n",
    "# Create an empty dataframe to hold the qid and instance_of_uuid values for statements to be deleted\n",
    "statements_to_delete = pd.DataFrame(columns=['qid', 'instance_of_uuid'])\n",
    "\n",
    "# Loop through each row of the prints_metadata dataframe and find the instance_of_uuid value in the vanderbot_metadata dataframe\n",
    "# If the instance_of_uuid value is found, copy the value of the instance_of column to the instance_of column in the prints_metadata dataframe\n",
    "for index in qid_list:\n",
    "    if index in vanderbot_metadata.index:\n",
    "        statements_to_delete = statements_to_delete.append({'qid': index, 'instance_of_uuid': statement_dict[index]}, ignore_index=True)\n",
    "    else:\n",
    "        print('ERROR: ' + index + ' not found in vanderbot_metadata')\n",
    "        error_messages += 'ERROR: ' + index + ' not found in vanderbot_metadata\\n'\n",
    "        continue\n",
    "\n",
    "    # Change the value from \"image\" (Q478798) to \"print\" (Q11060274)\n",
    "    vanderbot_metadata.at[index, 'instance_of'] = 'Q11060274'\n",
    "    # Change the value of the instance_of_uuid column to the empty string\n",
    "    vanderbot_metadata.at[index, 'instance_of_uuid'] = ''\n",
    "    # Change the value of the instance_of_ref1_hash column to the empty string\n",
    "    vanderbot_metadata.at[index, 'instance_of_ref1_hash'] = ''\n",
    "\n",
    "# Write the statements_to_delete dataframe to a CSV file\n",
    "statements_to_delete.to_csv('deletions.csv', index=False)\n",
    "\n",
    "# Write the updated vanderbot_metadata dataframe to a CSV file\n",
    "vanderbot_metadata.to_csv(path_to_vanderbot_metadata, index=False)\n",
    "\n",
    "# Write the error messages to a text file\n",
    "with open('error_messages.txt', 'w') as f:\n",
    "    f.write(error_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this step, use vanderdeletebot.py to delete the P31 print statements.\n",
    "Then run vanderbot.py to create the new P31 poster statements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
