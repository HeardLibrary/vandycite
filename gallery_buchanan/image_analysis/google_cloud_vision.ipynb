{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the landing page for Google Cloud Vision\n",
    "# https://cloud.google.com/vision/\n",
    "# From it you can try the api by dragging and dropping an image into the browser. You can then \n",
    "# view the JSON response, which was helpfule at first to understand the structure of the response.\n",
    "\n",
    "# The following tutorial contains critical information about enabling the API and creating a role\n",
    "# for the service account to allow it access. This is followed by creating a service account key.\n",
    "# https://cloud.google.com/vision/docs/detect-labels-image-client-libraries\n",
    "\n",
    "# I didn't actually do this tutorial, but it was useful to understand the order of operations that\n",
    "# needed to be done prior to writing to the API.\n",
    "# https://www.cloudskillsboost.google/focuses/2457?parent=catalog&utm_source=vision&utm_campaign=cloudapi&utm_medium=webpage\n",
    "# Because I'm using the Python client library, the part about setting up the request body was irrelevant. \n",
    "# But the stuff about uploading the files to the bucket, making it publicly accessible, etc. was helpful.\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "# Reference for Google Cloud Vision Python client https://cloud.google.com/python/docs/reference/vision/latest\n",
    "from google.cloud import vision\n",
    "from google.cloud import vision_v1\n",
    "from google.cloud.vision_v1 import AnnotateImageResponse\n",
    "\n",
    "# Import from Google oauth library\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell only needs to be run if the credentials are being loaded from the environmental variable. It seems cleaner to load the file directly into the script as credentials (in the next cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/baskausj/image-analysis-376619-193859a33600.json\n"
     ]
    }
   ],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/baskausj/image-analysis-376619-193859a33600.json'\n",
    "print(os.environ['GOOGLE_APPLICATION_CREDENTIALS'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this cell in preference to the one above to load the credentials directly into the script as a credentials object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = '/Users/baskausj/image-analysis-376619-193859a33600.json'\n",
    "\n",
    "# Create a credentials object\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API documentation https://cloud.google.com/python/docs/reference/vision/latest/google.cloud.vision_v1.services.image_annotator.ImageAnnotatorClient#methods\n",
    "# The first two versions have no arguments and the credentials are loaded from the environment variable.\n",
    "#client = vision.ImageAnnotatorClient()\n",
    "# Used this specific v1 to get the JSON conversion to work\n",
    "#client = vision_v1.ImageAnnotatorClient()\n",
    "# Use this line instead of the one above to load the credentials directly from the file\n",
    "client = vision_v1.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "# To access the images, they should be stored in a Google Cloud Storage bucket that is set up for public access.\n",
    "# It's also possible to use a publicly accessible URL, but that seems to be unreliable.\n",
    "# The storage costs for a few images are negligible.\n",
    "#image_uri = 'gs://vu-gallery/1979.0326P.jpg' # landscape\n",
    "#image_uri = 'gs://vu-gallery/card.jpg' # business card\n",
    "#image_uri = 'gs://vu-gallery/1979.0655P.jpg' # St. Sebastian\n",
    "#image_uri = 'gs://vu-gallery/2004.017.jpg' # sketch\n",
    "image_uri = 'gs://vu-gallery/1974.027.jpg' # sketch of artist with dog\n",
    "\n",
    "# Here is the API documentation for the Feature object.\n",
    "# https://cloud.google.com/vision/docs/reference/rest/v1/Feature\n",
    "#analysis_type = vision.Feature.Type.FACE_DETECTION\n",
    "#analysis_type = vision.Feature.Type.LABEL_DETECTION\n",
    "analysis_type = vision.Feature.Type.OBJECT_LOCALIZATION\n",
    "\n",
    "# This API documentation isn't exactly the one for the .annotate_image method, but it's close enough.\n",
    "# https://cloud.google.com/vision/docs/reference/rest/v1/projects.images/annotate\n",
    "# In particular, it links to the AnnotateImageRequest object, which is what we need to pass to the annotate_image method.\n",
    "response = client.annotate_image({\n",
    "  'image': {'source': {'image_uri': image_uri}},\n",
    "  'features': [{'type_': analysis_type}]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"localizedObjectAnnotations\": [\n",
      "    {\n",
      "      \"mid\": \"/m/0bt9lr\",\n",
      "      \"name\": \"Dog\",\n",
      "      \"score\": 0.8362394,\n",
      "      \"boundingPoly\": {\n",
      "        \"normalizedVertices\": [\n",
      "          {\n",
      "            \"x\": 0.60463864,\n",
      "            \"y\": 0.38959154\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.98275715,\n",
      "            \"y\": 0.38959154\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.98275715,\n",
      "            \"y\": 0.91793966\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.60463864,\n",
      "            \"y\": 0.91793966\n",
      "          }\n",
      "        ],\n",
      "        \"vertices\": []\n",
      "      },\n",
      "      \"languageCode\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"mid\": \"/m/09j2d\",\n",
      "      \"name\": \"Clothing\",\n",
      "      \"score\": 0.609878,\n",
      "      \"boundingPoly\": {\n",
      "        \"normalizedVertices\": [\n",
      "          {\n",
      "            \"x\": 0.13458158,\n",
      "            \"y\": 0.2999172\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.6982942,\n",
      "            \"y\": 0.2999172\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.6982942,\n",
      "            \"y\": 0.81593204\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.13458158,\n",
      "            \"y\": 0.81593204\n",
      "          }\n",
      "        ],\n",
      "        \"vertices\": []\n",
      "      },\n",
      "      \"languageCode\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"mid\": \"/m/01g317\",\n",
      "      \"name\": \"Person\",\n",
      "      \"score\": 0.58853036,\n",
      "      \"boundingPoly\": {\n",
      "        \"normalizedVertices\": [\n",
      "          {\n",
      "            \"x\": 0.08482196,\n",
      "            \"y\": 0.12571836\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.87521523,\n",
      "            \"y\": 0.12571836\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.87521523,\n",
      "            \"y\": 0.91473573\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.08482196,\n",
      "            \"y\": 0.91473573\n",
      "          }\n",
      "        ],\n",
      "        \"vertices\": []\n",
      "      },\n",
      "      \"languageCode\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"mid\": \"/m/02dl1y\",\n",
      "      \"name\": \"Hat\",\n",
      "      \"score\": 0.50328195,\n",
      "      \"boundingPoly\": {\n",
      "        \"normalizedVertices\": [\n",
      "          {\n",
      "            \"x\": 0.2610112,\n",
      "            \"y\": 0.11289233\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.6261362,\n",
      "            \"y\": 0.11289233\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.6261362,\n",
      "            \"y\": 0.32247016\n",
      "          },\n",
      "          {\n",
      "            \"x\": 0.2610112,\n",
      "            \"y\": 0.32247016\n",
      "          }\n",
      "        ],\n",
      "        \"vertices\": []\n",
      "      },\n",
      "      \"languageCode\": \"\"\n",
      "    }\n",
      "  ],\n",
      "  \"faceAnnotations\": [],\n",
      "  \"landmarkAnnotations\": [],\n",
      "  \"logoAnnotations\": [],\n",
      "  \"labelAnnotations\": [],\n",
      "  \"textAnnotations\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# The API response is a protobuf object, which is not JSON serializable.\n",
    "# So we need to convert it to a JSON serializable object.\n",
    "# Solution from https://stackoverflow.com/a/65728119\n",
    "response_json = AnnotateImageResponse.to_json(response)\n",
    "\n",
    "# The structure of the response is detailed in the API documentation here:\n",
    "# https://cloud.google.com/vision/docs/reference/rest/v1/AnnotateImageResponse\n",
    "# The various bits are detailed for each feature type.\n",
    "# Here's the documentation for entity annotations, with a link to the BoundyPoly object.\n",
    "# https://cloud.google.com/vision/docs/reference/rest/v1/AnnotateImageResponse#EntityAnnotation\n",
    "response_struct = json.loads(response_json)\n",
    "print(response_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f96c65e2c1d4fcba82e9525c1be2fd15c6a14102f9c31bd3457b5f48c526190"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
