{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the images to a local directory\n",
    "\n",
    "NOTE: this only needs to be done once for a given set of images. Once they are loaded into the bucket it doesn't need to be run again.\n",
    "\n",
    "This code uses a list of accession numbers (found as a column in a CSV file) to generate IIIF Image API (v2) URLs for JPEG images that are 1000 pixels in the shortest dimension, then download them into a local directory.\n",
    "\n",
    "After generating and downloading the images, they need to be uploaded to the Google Cloud bucket used in the Vision analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_filename</th>\n",
       "      <th>qid</th>\n",
       "      <th>accession_number</th>\n",
       "      <th>rank</th>\n",
       "      <th>kilobytes</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>photo_inception</th>\n",
       "      <th>extension</th>\n",
       "      <th>directory</th>\n",
       "      <th>label_en</th>\n",
       "      <th>commons_image_name</th>\n",
       "      <th>iiif_manifest</th>\n",
       "      <th>manifest_label</th>\n",
       "      <th>upload_notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commons_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M122562148</th>\n",
       "      <td>1956-001.tif</td>\n",
       "      <td>Q102961253</td>\n",
       "      <td>1956.001</td>\n",
       "      <td>primary</td>\n",
       "      <td>73531</td>\n",
       "      <td>2611</td>\n",
       "      <td>4805</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>tif</td>\n",
       "      <td>1956</td>\n",
       "      <td>A group of muffs and other articles of dress o...</td>\n",
       "      <td>A group of muffs and other articles of dress o...</td>\n",
       "      <td>https://iiif-manifest.library.vanderbilt.edu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M122617251</th>\n",
       "      <td>1956.002.tif</td>\n",
       "      <td>Q103296446</td>\n",
       "      <td>1956.002</td>\n",
       "      <td>primary</td>\n",
       "      <td>86058</td>\n",
       "      <td>4471</td>\n",
       "      <td>3284</td>\n",
       "      <td>2012-10-17</td>\n",
       "      <td>tif</td>\n",
       "      <td>1956</td>\n",
       "      <td>A Flower Piece (after Jan van Huysum)</td>\n",
       "      <td>A Flower Piece (after Jan van Huysum) - Vander...</td>\n",
       "      <td>https://iiif-manifest.library.vanderbilt.edu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M122641532</th>\n",
       "      <td>1956-003.tif</td>\n",
       "      <td>Q103297456</td>\n",
       "      <td>1956.003</td>\n",
       "      <td>primary</td>\n",
       "      <td>47806</td>\n",
       "      <td>3600</td>\n",
       "      <td>2265</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>tif</td>\n",
       "      <td>1956</td>\n",
       "      <td>Bishop Hacket</td>\n",
       "      <td>Bishop Hacket - Vanderbilt Fine Arts Gallery -...</td>\n",
       "      <td>https://iiif-manifest.library.vanderbilt.edu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M122695514</th>\n",
       "      <td>1956.004.jpg</td>\n",
       "      <td>Q103310070</td>\n",
       "      <td>1956.004</td>\n",
       "      <td>primary</td>\n",
       "      <td>122</td>\n",
       "      <td>696</td>\n",
       "      <td>452</td>\n",
       "      <td>2010-02-22</td>\n",
       "      <td>jpg</td>\n",
       "      <td>1956</td>\n",
       "      <td>The Raising of Lazarus (after Leandro Bassano)</td>\n",
       "      <td>The Raising of Lazarus (after Leandro Bassano)...</td>\n",
       "      <td>https://iiif-manifest.library.vanderbilt.edu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M122611522</th>\n",
       "      <td>1956.006.jpg</td>\n",
       "      <td>Q102974173</td>\n",
       "      <td>1956.006</td>\n",
       "      <td>primary</td>\n",
       "      <td>58</td>\n",
       "      <td>365</td>\n",
       "      <td>436</td>\n",
       "      <td>2010-02-22</td>\n",
       "      <td>jpg</td>\n",
       "      <td>1956</td>\n",
       "      <td>The Farmhouse by the Water</td>\n",
       "      <td>The Farmhouse by the Water - Vanderbilt Fine A...</td>\n",
       "      <td>https://iiif-manifest.library.vanderbilt.edu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           local_filename         qid accession_number     rank kilobytes  \\\n",
       "commons_id                                                                  \n",
       "M122562148   1956-001.tif  Q102961253         1956.001  primary     73531   \n",
       "M122617251   1956.002.tif  Q103296446         1956.002  primary     86058   \n",
       "M122641532   1956-003.tif  Q103297456         1956.003  primary     47806   \n",
       "M122695514   1956.004.jpg  Q103310070         1956.004  primary       122   \n",
       "M122611522   1956.006.jpg  Q102974173         1956.006  primary        58   \n",
       "\n",
       "           height width photo_inception extension directory  \\\n",
       "commons_id                                                    \n",
       "M122562148   2611  4805      2020-07-23       tif      1956   \n",
       "M122617251   4471  3284      2012-10-17       tif      1956   \n",
       "M122641532   3600  2265      2020-08-18       tif      1956   \n",
       "M122695514    696   452      2010-02-22       jpg      1956   \n",
       "M122611522    365   436      2010-02-22       jpg      1956   \n",
       "\n",
       "                                                     label_en  \\\n",
       "commons_id                                                      \n",
       "M122562148  A group of muffs and other articles of dress o...   \n",
       "M122617251              A Flower Piece (after Jan van Huysum)   \n",
       "M122641532                                      Bishop Hacket   \n",
       "M122695514     The Raising of Lazarus (after Leandro Bassano)   \n",
       "M122611522                         The Farmhouse by the Water   \n",
       "\n",
       "                                           commons_image_name  \\\n",
       "commons_id                                                      \n",
       "M122562148  A group of muffs and other articles of dress o...   \n",
       "M122617251  A Flower Piece (after Jan van Huysum) - Vander...   \n",
       "M122641532  Bishop Hacket - Vanderbilt Fine Arts Gallery -...   \n",
       "M122695514  The Raising of Lazarus (after Leandro Bassano)...   \n",
       "M122611522  The Farmhouse by the Water - Vanderbilt Fine A...   \n",
       "\n",
       "                                                iiif_manifest manifest_label  \\\n",
       "commons_id                                                                     \n",
       "M122562148  https://iiif-manifest.library.vanderbilt.edu/g...            NaN   \n",
       "M122617251  https://iiif-manifest.library.vanderbilt.edu/g...            NaN   \n",
       "M122641532  https://iiif-manifest.library.vanderbilt.edu/g...            NaN   \n",
       "M122695514  https://iiif-manifest.library.vanderbilt.edu/g...            NaN   \n",
       "M122611522  https://iiif-manifest.library.vanderbilt.edu/g...            NaN   \n",
       "\n",
       "           upload_notes  \n",
       "commons_id               \n",
       "M122562148          NaN  \n",
       "M122617251          NaN  \n",
       "M122641532          NaN  \n",
       "M122695514          NaN  \n",
       "M122611522          NaN  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import shutil # high-level file operations\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image data into a dataframe\n",
    "base_path = '/Users/baskausj/github/vandycite/gallery_buchanan/image_analysis/'\n",
    "download_path = '/Users/baskausj/Downloads/'\n",
    "\n",
    "# Load the source image data into a dataframe\n",
    "source_image_dataframe = pd.read_csv(base_path + 'combined_images.csv', dtype=str)\n",
    "# Set the commons_id column as the index\n",
    "source_image_dataframe = source_image_dataframe.set_index('commons_id')\n",
    "\n",
    "source_image_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986.076\n",
      "image_url https://iiif.library.vanderbilt.edu/iiif/2/gallery%2F1986%2F1986.076.tif/full/!1339,1339/0/default.jpg\n",
      "\n",
      "1979.0324P\n",
      "image_url https://iiif.library.vanderbilt.edu/iiif/2/gallery%2F1979%2F1979.0324P.tif/full/!1217,1217/0/default.jpg\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import CSV data as a dataframe.\n",
    "accession_dataframe = pd.read_csv(base_path + 'test_accession_numbers.csv', dtype=str)\n",
    "\n",
    "# Create a dataframe to hold the accession numbers and dimensions\n",
    "accession_dimensions_dataframe = pd.DataFrame(columns=['accession_number', 'height', 'width'])\n",
    "\n",
    "# Loop through the dataframe rows and download the images.\n",
    "for index, row in accession_dataframe.iterrows():\n",
    "    accession_number = row['accession_number']\n",
    "    print(accession_number)\n",
    "\n",
    "    # Look up the image data in the source image dataframe.\n",
    "    # In cases where there are two images, we want the primary image.\n",
    "    image_series = source_image_dataframe.loc[(source_image_dataframe['accession_number'] == accession_number) & (source_image_dataframe['rank'] == 'primary')]\n",
    "    manifest_url = image_series['iiif_manifest'][0]\n",
    "\n",
    "    # get the manifest from the manifest url\n",
    "    manifest = requests.get(manifest_url).json()\n",
    "    #print(json.dumps(manifest, indent=2))\n",
    "    service_url = manifest['sequences'][0]['canvases'][0]['images'][0]['resource']['service']['@id']\n",
    "    # Because of the error in original manifests, replace version 3 with version 2 in the URL.\n",
    "    service_url = service_url.replace('/3/', '/2/')\n",
    "    #print('service_url', service_url)\n",
    "\n",
    "    # Determine the maximum and minimum dimensions of the image.\n",
    "    height = image_series['height'][0]\n",
    "    #print('height', height)\n",
    "    width = image_series['width'][0]\n",
    "    #print('width', width)\n",
    "    shortest_dimension = min(int(height), int(width))\n",
    "    longest_dimension = max(int(height), int(width))\n",
    "    #print('shortest_dimension', shortest_dimension)\n",
    "\n",
    "    # We want to know what the largest dimension needs to be for the shortest dimension to be 1000 pixels.\n",
    "    # If that calculation makes the longest dimension longer than the actual longest dimension, \n",
    "    # then we want to use the actual longest dimension.\n",
    "    # If the shortest dimension is already less than 1000 pixels, then we will just use the longest dimension as is.\n",
    "    if shortest_dimension > 1000:\n",
    "        size = int(1000 * (longest_dimension / shortest_dimension))\n",
    "        if size > longest_dimension:\n",
    "            size = longest_dimension\n",
    "    else:\n",
    "        size = longest_dimension\n",
    "    #print('size', size)\n",
    "\n",
    "    # construct the image url using the \"!\" size option, that keeps the aspect ratio but sizes to the maximum dimension.\n",
    "    image_url = service_url + '/full/!' + str(size) + ',' + str(size) + '/0/default.jpg'\n",
    "    print('image_url', image_url)\n",
    "    print()\n",
    "        \n",
    "    # retrieve the image from the IIIF server\n",
    "    image_object = requests.get(image_url, stream=True).raw\n",
    "\n",
    "    # Find the image dimensions\n",
    "    image = Image.open(image_object)\n",
    "    reduced_width, reduced_height = image.size\n",
    "\n",
    "    # save the image as a JPEG file]\n",
    "    with open(download_path + 'google_vision_images/' + accession_number + '.jpg', 'wb') as out_file:\n",
    "        shutil.copyfileobj(image_object, out_file)\n",
    "\n",
    "    # Add the accession number and dimensions to the dataframe\n",
    "    accession_dimensions_dataframe = accession_dimensions_dataframe.append({'accession_number': accession_number, 'max_height': height, 'max_width': width, 'height': reduced_height, 'width': reduced_width}, ignore_index=True)\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "accession_dimensions_dataframe.to_csv(base_path + 'accession_dimensions.csv', index=False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Vision image analysis\n",
    "\n",
    "The first cell retrieves the service key, creates a credentials object, then uses it to authenticate and create a `client` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the landing page for Google Cloud Vision\n",
    "# https://cloud.google.com/vision/\n",
    "# From it you can try the api by dragging and dropping an image into the browser. You can then \n",
    "# view the JSON response, which was helpfule at first to understand the structure of the response.\n",
    "\n",
    "# The following tutorial contains critical information about enabling the API and creating a role\n",
    "# for the service account to allow it access. This is followed by creating a service account key.\n",
    "# https://cloud.google.com/vision/docs/detect-labels-image-client-libraries\n",
    "\n",
    "# I didn't actually do this tutorial, but it was useful to understand the order of operations that\n",
    "# needed to be done prior to writing to the API.\n",
    "# https://www.cloudskillsboost.google/focuses/2457?parent=catalog&utm_source=vision&utm_campaign=cloudapi&utm_medium=webpage\n",
    "# Because I'm using the Python client library, the part about setting up the request body was irrelevant. \n",
    "# But the stuff about uploading the files to the bucket, making it publicly accessible, etc. was helpful.\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "# Reference for Google Cloud Vision Python client https://cloud.google.com/python/docs/reference/vision/latest\n",
    "from google.cloud import vision\n",
    "from google.cloud import vision_v1\n",
    "from google.cloud.vision_v1 import AnnotateImageResponse\n",
    "\n",
    "# Import from Google oauth library\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Extract the annotation data from a hit and turn it into a row in the dataframe\n",
    "def extract_object_localization_data(accession_number, annotation, width, height):\n",
    "    #print('annotation', annotation)\n",
    "    description = annotation['name']\n",
    "    score = annotation['score']\n",
    "    left_x = annotation['boundingPoly']['normalizedVertices'][0]['x']\n",
    "    top_y = annotation['boundingPoly']['normalizedVertices'][0]['y']\n",
    "    right_x = annotation['boundingPoly']['normalizedVertices'][2]['x']\n",
    "    bottom_y = annotation['boundingPoly']['normalizedVertices'][2]['y']\n",
    "    #print('description', description)\n",
    "    #print('score', score)\n",
    "    #print('left_x', left_x)\n",
    "    #print('top_y', top_y)\n",
    "    #print('right_x', right_x)\n",
    "    #print('bottom_y', bottom_y)\n",
    "    #print()\n",
    "\n",
    "    row = {'accession_number': accession_number, 'description': description, 'score': score, 'rel_left_x': left_x, 'rel_right_x': right_x, 'rel_top_y': top_y, 'rel_bottom_y': bottom_y, 'abs_left_x': round(left_x * width), 'abs_right_x': round(right_x * width), 'abs_top_y': round(top_y * height), 'abs_bottom_y': round(bottom_y * height)}\n",
    "    return row\n",
    "\n",
    "def extract_face_detection_data(accession_number, annotation, width, height):\n",
    "    score = annotation['detectionConfidence']\n",
    "    left_x = annotation['boundingPoly']['vertices'][0]['x']\n",
    "    top_y = annotation['boundingPoly']['vertices'][0]['y']\n",
    "    right_x = annotation['boundingPoly']['vertices'][2]['x']\n",
    "    bottom_y = annotation['boundingPoly']['vertices'][2]['y']\n",
    "    roll_angle = annotation['rollAngle']\n",
    "    pan_angle = annotation['panAngle']\n",
    "    tilt_angle = annotation['tiltAngle']\n",
    "    landmarking_confidence = annotation['landmarkingConfidence']\n",
    "    joy_likelihood = annotation['joyLikelihood']\n",
    "    sorrow_likelihood = annotation['sorrowLikelihood']\n",
    "    anger_likelihood = annotation['angerLikelihood']\n",
    "    surprise_likelihood = annotation['surpriseLikelihood']\n",
    "    under_exposed_likelihood = annotation['underExposedLikelihood']\n",
    "    blurred_likelihood = annotation['blurredLikelihood']\n",
    "    headwear_likelihood = annotation['headwearLikelihood']\n",
    "\n",
    "    row = {'accession_number': accession_number, 'score': score, \n",
    "           'rel_left_x': left_x / width, 'rel_right_x': right_x / width, 'rel_top_y': top_y / height, 'rel_bottom_y': bottom_y /height,\n",
    "           'abs_left_x': left_x, 'abs_right_x': right_x, 'abs_top_y': top_y, 'abs_bottom_y': bottom_y,\n",
    "           'roll_angle': roll_angle, 'pan_angle': pan_angle, 'tilt_angle': tilt_angle,\n",
    "           'landmarking_confidence': landmarking_confidence, 'joy_likelihood': joy_likelihood, \n",
    "           'sorrow_likelihood': sorrow_likelihood, 'anger_likelihood': anger_likelihood, \n",
    "           'surprise_likelihood': surprise_likelihood, 'under_exposed_likelihood': under_exposed_likelihood,\n",
    "           'blurred_likelihood': blurred_likelihood, 'headwear_likelihood': headwear_likelihood}\n",
    "    return row\n",
    "\n",
    "def extract_label_detection_data(accession_number, annotation):\n",
    "    mid = annotation['mid']\n",
    "    description = annotation['description']\n",
    "    score = annotation['score']\n",
    "    topicality = annotation['topicality']\n",
    "    row = {'accession_number': accession_number, 'mid': mid, 'description': description, 'score': score, 'topicality': topicality}\n",
    "    return row\n",
    "\n",
    "def extract_text_detection_data(accession_number, annotation, width, height):\n",
    "    locale = annotation['locale']\n",
    "    description = annotation['description']\n",
    "    left_x = annotation['boundingPoly']['vertices'][0]['x']\n",
    "    top_y = annotation['boundingPoly']['vertices'][0]['y']\n",
    "    right_x = annotation['boundingPoly']['vertices'][2]['x']\n",
    "    bottom_y = annotation['boundingPoly']['vertices'][2]['y']\n",
    "    row = {'accession_number': accession_number, 'locale': locale, 'description': description, \n",
    "           'rel_left_x': left_x / width, 'rel_right_x': right_x / width, 'rel_top_y': top_y / height, 'rel_bottom_y': bottom_y / height,\n",
    "           'abs_left_x': left_x, 'abs_right_x': right_x, 'abs_top_y': top_y, 'abs_bottom_y': bottom_y,\n",
    "           }\n",
    "    return row\n",
    "\n",
    "# Customize for your own computer\n",
    "user_dir = 'baskausj' # Enter your user directory name here\n",
    "base_path = '/Users/baskausj/github/vandycite/gallery_buchanan/image_analysis/' # Location of the accession number data file\n",
    "annotations_base_url = 'https://baskaufs.github.io/iiif/baskauf/'\n",
    "\n",
    "# Set the path to the service account key\n",
    "key_path = '/Users/' + user_dir + '/image-analysis-376619-193859a33600.json'\n",
    "\n",
    "# Create a credentials object from the service account key\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "\n",
    "# API documentation https://cloud.google.com/python/docs/reference/vision/latest/google.cloud.vision_v1.services.image_annotator.ImageAnnotatorClient#methods\n",
    "# The first two versions have no arguments and the credentials are loaded from the environment variable.\n",
    "#client = vision.ImageAnnotatorClient()\n",
    "# Used this specific v1 to get the JSON conversion to work\n",
    "#client = vision_v1.ImageAnnotatorClient()\n",
    "# Use this line instead of the one above to load the credentials directly from the file\n",
    "client = vision_v1.ImageAnnotatorClient(credentials=credentials)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the source data from a CSV. The critical column needed here is the `accession_number` column, since it is the one that was used to construct the image file name for the uploaded test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession_number</th>\n",
       "      <th>max_height</th>\n",
       "      <th>max_width</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956.012</td>\n",
       "      <td>768</td>\n",
       "      <td>1019</td>\n",
       "      <td>768</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956.043</td>\n",
       "      <td>4266</td>\n",
       "      <td>3311</td>\n",
       "      <td>1288</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971.002</td>\n",
       "      <td>2925</td>\n",
       "      <td>4401</td>\n",
       "      <td>1000</td>\n",
       "      <td>1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979.0016</td>\n",
       "      <td>2944</td>\n",
       "      <td>4445</td>\n",
       "      <td>999</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979.0071</td>\n",
       "      <td>1780</td>\n",
       "      <td>2460</td>\n",
       "      <td>1000</td>\n",
       "      <td>1382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accession_number max_height max_width height width\n",
       "0         1956.012        768      1019    768  1019\n",
       "1         1956.043       4266      3311   1288  1000\n",
       "2         1971.002       2925      4401   1000  1504\n",
       "3        1979.0016       2944      4445    999  1509\n",
       "4        1979.0071       1780      2460   1000  1382"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CSV data as a dataframe.\n",
    "accession_dataframe = pd.read_csv(base_path + 'accession_dimensions.csv', dtype=str)\n",
    "accession_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is for testing the API with a single image\n",
    "# Don't run this cell if you want to run the whole dataframe\n",
    "accession_dataframe = accession_dataframe.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all of the accession numbers and perform the analysis on each of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accession_number 1956.012\n",
      "accession_number 1956.043\n",
      "accession_number 1971.002\n",
      "accession_number 1979.0016\n",
      "accession_number 1979.0071\n",
      "accession_number 1979.0190P\n",
      "accession_number 1979.0236P\n",
      "accession_number 1979.0238P\n",
      "accession_number 1979.0243P\n",
      "accession_number 1979.0249P\n",
      "accession_number 1979.0282P\n",
      "accession_number 1979.0322P\n",
      "accession_number 1979.0524P\n",
      "accession_number 1979.0553\n",
      "accession_number 1979.0634P\n",
      "accession_number 1979.0721P\n",
      "accession_number 1979.0840P\n",
      "accession_number 1979.1178P\n",
      "accession_number 1979.1216P\n",
      "accession_number 1979.1225P\n",
      "accession_number 1979.1232P\n",
      "accession_number 1980.037\n",
      "accession_number 1986.054\n",
      "accession_number 1992.114\n",
      "accession_number 1995.010\n",
      "accession_number 2002.009\n",
      "accession_number 2003.036\n",
      "accession_number 2017.001.058\n",
      "accession_number 2018.002\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe to hold the annotations\n",
    "object_localization_dataframe = pd.DataFrame(columns=['accession_number', 'description', 'score', 'rel_left_x', 'rel_right_x', 'rel_top_y', 'rel_bottom_y', 'abs_left_x', 'abs_right_x', 'abs_top_y', 'abs_bottom_y'])\n",
    "face_detection_dataframe = pd.DataFrame(columns=['accession_number', 'score', 'rel_left_x', 'rel_right_x', 'rel_top_y', 'rel_bottom_y', 'abs_left_x', 'abs_right_x', 'abs_top_y', 'abs_bottom_y', 'roll_angle', 'pan_angle', 'tilt_angle', 'landmarking, confidence', 'joy_likelihood', 'sorrow_likelihood', 'anger_likelihood', 'surprise_likelihood', 'under_exposed_likelihood', 'blurred_likelihood', 'headwear_likelihood'])\n",
    "label_detection_dataframe = pd.DataFrame(columns=['accession_number', 'mid', 'description', 'score', 'topicality'])\n",
    "text_detection_dataframe = pd.DataFrame(columns=['accession_number', 'locale', 'description', 'rel_left_x', 'rel_right_x', 'rel_top_y', 'rel_bottom_y', 'abs_left_x', 'abs_right_x', 'abs_top_y', 'abs_bottom_y'])\n",
    "\n",
    "# Loop through the dataframe rows and download the images.\n",
    "for index, row in accession_dataframe.iterrows():\n",
    "    accession_number = row['accession_number']\n",
    "    print('accession_number', accession_number)\n",
    "    width = int(row['width'])\n",
    "    height = int(row['height'])\n",
    "\n",
    "    # To access the images, they should be stored in a Google Cloud Storage bucket that is set up for public access.\n",
    "    # It's also possible to use a publicly accessible URL, but that seems to be unreliable.\n",
    "    # The storage costs for a few images are negligible.\n",
    "\n",
    "    # Construct the path to the image file\n",
    "    image_uri = 'gs://vu-gallery/' + accession_number + '.jpg'\n",
    "    #print('image_uri', image_uri)\n",
    "    \n",
    "    # Here is the API documentation for the Feature object.\n",
    "    # https://cloud.google.com/vision/docs/reference/rest/v1/Feature\n",
    "    #analysis_type = vision.Feature.Type.FACE_DETECTION\n",
    "    #analysis_type = vision.Feature.Type.LABEL_DETECTION\n",
    "    #analysis_type = vision.Feature.Type.OBJECT_LOCALIZATION\n",
    "\n",
    "    # This API documentation isn't exactly the one for the .annotate_image method, but it's close enough.\n",
    "    # https://cloud.google.com/vision/docs/reference/rest/v1/projects.images/annotate\n",
    "    # In particular, it links to the AnnotateImageRequest object, which is what we need to pass to the annotate_image method.\n",
    "    response = client.annotate_image({\n",
    "    'image': {'source': {'image_uri': image_uri}},\n",
    "    'features': [\n",
    "        {'type_': vision.Feature.Type.OBJECT_LOCALIZATION},\n",
    "        {'type_': vision.Feature.Type.FACE_DETECTION},\n",
    "        {'type_': vision.Feature.Type.LABEL_DETECTION},\n",
    "        {'type_': vision.Feature.Type.TEXT_DETECTION}  \n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # The API response is a protobuf object, which is not JSON serializable.\n",
    "    # So we need to convert it to a JSON serializable object.\n",
    "    # Solution from https://stackoverflow.com/a/65728119\n",
    "    response_json = AnnotateImageResponse.to_json(response)\n",
    "\n",
    "    # The structure of the response is detailed in the API documentation here:\n",
    "    # https://cloud.google.com/vision/docs/reference/rest/v1/AnnotateImageResponse\n",
    "    # The various bits are detailed for each feature type.\n",
    "    # Here's the documentation for entity annotations, with a link to the BoundyPoly object.\n",
    "    # https://cloud.google.com/vision/docs/reference/rest/v1/AnnotateImageResponse#EntityAnnotation\n",
    "    response_struct = json.loads(response_json)\n",
    "\n",
    "    # Object localization\n",
    "    # -------------------\n",
    "\n",
    "    for annotation in response_struct['localizedObjectAnnotations']:\n",
    "        row = extract_object_localization_data(accession_number, annotation, width, height)\n",
    "        object_localization_dataframe = object_localization_dataframe.append(row, ignore_index=True)\n",
    "    \n",
    "    # Write the annotations to a CSV file after every image in case the process is interrupted.\n",
    "    object_localization_dataframe.to_csv(base_path + 'object_localization.csv', index=False)\n",
    "    \n",
    "    # Face detection\n",
    "    # --------------\n",
    "    '''\n",
    "    analysis_type = vision.Feature.Type.FACE_DETECTION\n",
    "    response = client.annotate_image({\n",
    "    'image': {'source': {'image_uri': image_uri}},\n",
    "    'features': [{'type_': analysis_type}]\n",
    "    })\n",
    "    response_json = AnnotateImageResponse.to_json(response)\n",
    "    response_struct = json.loads(response_json)\n",
    "    '''\n",
    "    for annotation in response_struct['faceAnnotations']:\n",
    "        row = extract_face_detection_data(accession_number, annotation, width, height)\n",
    "        face_detection_dataframe = face_detection_dataframe.append(row, ignore_index=True)\n",
    "    \n",
    "    # Write the annotations to a CSV file after every image in case the process is interrupted.\n",
    "    face_detection_dataframe.to_csv(base_path + 'face_detection.csv', index=False)\n",
    "    \n",
    "    # Label detection\n",
    "    # ---------------\n",
    "    '''\n",
    "    analysis_type = vision.Feature.Type.LABEL_DETECTION\n",
    "    response = client.annotate_image({\n",
    "    'image': {'source': {'image_uri': image_uri}},\n",
    "    'features': [{'type_': analysis_type}]\n",
    "    })\n",
    "    response_json = AnnotateImageResponse.to_json(response)\n",
    "    response_struct = json.loads(response_json)\n",
    "    # print(json.dumps(response_struct, indent=2))\n",
    "    '''\n",
    "    for annotation in response_struct['labelAnnotations']:\n",
    "        row = extract_label_detection_data(accession_number, annotation)\n",
    "        label_detection_dataframe = label_detection_dataframe.append(row, ignore_index=True)\n",
    "    \n",
    "    # Write the annotations to a CSV file after every image in case the process is interrupted.\n",
    "    label_detection_dataframe.to_csv(base_path + 'label_detection.csv', index=False)\n",
    "    \n",
    "    # Text detection\n",
    "    # --------------\n",
    "    '''\n",
    "    analysis_type = vision.Feature.Type.TEXT_DETECTION\n",
    "    response = client.annotate_image({\n",
    "    'image': {'source': {'image_uri': image_uri}},\n",
    "    'features': [{'type_': analysis_type}]\n",
    "    })\n",
    "    response_json = AnnotateImageResponse.to_json(response)\n",
    "    response_struct = json.loads(response_json)\n",
    "    #print(json.dumps(response_struct, indent=2))\n",
    "    '''\n",
    "    for annotation in response_struct['textAnnotations']:\n",
    "        row = extract_text_detection_data(accession_number, annotation, width, height)\n",
    "        text_detection_dataframe = text_detection_dataframe.append(row, ignore_index=True)\n",
    "\n",
    "    # Write the annotations to a CSV file after every image in case the process is interrupted.\n",
    "    text_detection_dataframe.to_csv(base_path + 'text_detection.csv', index=False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create IIIF annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession_number</th>\n",
       "      <th>description</th>\n",
       "      <th>score</th>\n",
       "      <th>rel_left_x</th>\n",
       "      <th>rel_right_x</th>\n",
       "      <th>rel_top_y</th>\n",
       "      <th>rel_bottom_y</th>\n",
       "      <th>abs_left_x</th>\n",
       "      <th>abs_right_x</th>\n",
       "      <th>abs_top_y</th>\n",
       "      <th>abs_bottom_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956.012</td>\n",
       "      <td>Animal</td>\n",
       "      <td>0.774044</td>\n",
       "      <td>0.127650</td>\n",
       "      <td>0.322942</td>\n",
       "      <td>0.503521</td>\n",
       "      <td>0.736281</td>\n",
       "      <td>130</td>\n",
       "      <td>329</td>\n",
       "      <td>387</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956.012</td>\n",
       "      <td>Person</td>\n",
       "      <td>0.759243</td>\n",
       "      <td>0.293280</td>\n",
       "      <td>0.674474</td>\n",
       "      <td>0.089172</td>\n",
       "      <td>0.885919</td>\n",
       "      <td>299</td>\n",
       "      <td>687</td>\n",
       "      <td>68</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956.012</td>\n",
       "      <td>Animal</td>\n",
       "      <td>0.706436</td>\n",
       "      <td>0.064499</td>\n",
       "      <td>0.136466</td>\n",
       "      <td>0.488693</td>\n",
       "      <td>0.711381</td>\n",
       "      <td>66</td>\n",
       "      <td>139</td>\n",
       "      <td>375</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956.012</td>\n",
       "      <td>Animal</td>\n",
       "      <td>0.698519</td>\n",
       "      <td>0.178926</td>\n",
       "      <td>0.380322</td>\n",
       "      <td>0.607171</td>\n",
       "      <td>0.854251</td>\n",
       "      <td>182</td>\n",
       "      <td>388</td>\n",
       "      <td>466</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956.012</td>\n",
       "      <td>Animal</td>\n",
       "      <td>0.647411</td>\n",
       "      <td>0.296356</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.127383</td>\n",
       "      <td>0.887515</td>\n",
       "      <td>302</td>\n",
       "      <td>675</td>\n",
       "      <td>98</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accession_number description     score  rel_left_x  rel_right_x  rel_top_y  \\\n",
       "0         1956.012      Animal  0.774044    0.127650     0.322942   0.503521   \n",
       "1         1956.012      Person  0.759243    0.293280     0.674474   0.089172   \n",
       "2         1956.012      Animal  0.706436    0.064499     0.136466   0.488693   \n",
       "3         1956.012      Animal  0.698519    0.178926     0.380322   0.607171   \n",
       "4         1956.012      Animal  0.647411    0.296356     0.662300   0.127383   \n",
       "\n",
       "   rel_bottom_y  abs_left_x  abs_right_x  abs_top_y  abs_bottom_y  \n",
       "0      0.736281         130          329        387           565  \n",
       "1      0.885919         299          687         68           680  \n",
       "2      0.711381          66          139        375           546  \n",
       "3      0.854251         182          388        466           656  \n",
       "4      0.887515         302          675         98           682  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the object localization CSV file and display the first few rows.\n",
    "object_localization_dataframe = pd.read_csv(base_path + 'object_localization.csv')\n",
    "object_localization_dataframe.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession_number</th>\n",
       "      <th>max_height</th>\n",
       "      <th>max_width</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956.012</td>\n",
       "      <td>768</td>\n",
       "      <td>1019</td>\n",
       "      <td>768</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956.043</td>\n",
       "      <td>4266</td>\n",
       "      <td>3311</td>\n",
       "      <td>1288</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971.002</td>\n",
       "      <td>2925</td>\n",
       "      <td>4401</td>\n",
       "      <td>1000</td>\n",
       "      <td>1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979.0016</td>\n",
       "      <td>2944</td>\n",
       "      <td>4445</td>\n",
       "      <td>999</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979.0071</td>\n",
       "      <td>1780</td>\n",
       "      <td>2460</td>\n",
       "      <td>1000</td>\n",
       "      <td>1382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accession_number max_height max_width height width\n",
       "0         1956.012        768      1019    768  1019\n",
       "1         1956.043       4266      3311   1288  1000\n",
       "2         1971.002       2925      4401   1000  1504\n",
       "3        1979.0016       2944      4445    999  1509\n",
       "4        1979.0071       1780      2460   1000  1382"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accession_dataframe = pd.read_csv(base_path + 'accession_dimensions.csv', dtype=str)\n",
    "accession_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This line is for testing the API with a single image\n",
    "accession_dataframe = accession_dataframe.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the annotations, we need to convert the relative dimensions to the absolute pixel dimensions based on the canvas size.\n",
    "\n",
    "The canvas size is given as the dimensions of the full-sized image, which is reported as `max_height` and `max_width` in the dimensions CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1 of 29\n",
      "Processing image 2 of 29\n",
      "Processing image 3 of 29\n",
      "Processing image 4 of 29\n",
      "Processing image 5 of 29\n",
      "Processing image 6 of 29\n",
      "Processing image 7 of 29\n",
      "Processing image 8 of 29\n",
      "Processing image 9 of 29\n",
      "Processing image 10 of 29\n",
      "Processing image 11 of 29\n",
      "Processing image 12 of 29\n",
      "Processing image 13 of 29\n",
      "Processing image 14 of 29\n",
      "Processing image 15 of 29\n",
      "Processing image 16 of 29\n",
      "Processing image 17 of 29\n",
      "Processing image 18 of 29\n",
      "Processing image 19 of 29\n",
      "Processing image 20 of 29\n",
      "Processing image 21 of 29\n",
      "Processing image 22 of 29\n",
      "Processing image 23 of 29\n",
      "Processing image 24 of 29\n",
      "Processing image 25 of 29\n",
      "Processing image 26 of 29\n",
      "Processing image 27 of 29\n",
      "Processing image 28 of 29\n",
      "Processing image 29 of 29\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Loop through each accession number and create an annotation for each localized object.\n",
    "for image_index, image_row in accession_dataframe.iterrows():\n",
    "    print('Processing image ' + str(image_index + 1) + ' of ' + str(len(accession_dataframe)))\n",
    "    # Build the resources list for the annotations.\n",
    "    resources = []\n",
    "    \n",
    "    # Loop through each object in the image.\n",
    "    for object_index, object_row in object_localization_dataframe.iterrows():\n",
    "        if object_row['accession_number'] != image_row['accession_number']:\n",
    "            continue\n",
    "\n",
    "        # Create a W3C fragment selector for the annotation.\n",
    "        # https://www.w3.org/TR/annotation-model/#fragment-selector\n",
    "        # Calculate the upper left x and y in absolute canvas coordinates.\n",
    "        x = str(round(object_row['rel_left_x'] * float(image_row['max_width'])))\n",
    "        y = str(round(object_row['rel_top_y'] * float(image_row['max_height'])))\n",
    "\n",
    "        # Calculate the width and height in absolute canvas coordinates.\n",
    "        width = str(round((object_row['rel_right_x'] - object_row['rel_left_x']) * float(image_row['max_width'])))\n",
    "        height = str(round((object_row['rel_bottom_y'] - object_row['rel_top_y']) * float(image_row['max_height'])))\n",
    "\n",
    "        fragment_selector = 'xywh=' + x + ',' + y + ',' + width + ',' + height\n",
    "\n",
    "        # Build the annotation.\n",
    "        on_value = {\n",
    "            '@type': 'oa:SpecificResource',\n",
    "            'full': 'https://iiif-manifest.library.vanderbilt.edu/gallery/' + image_row['accession_number'].split('.')[0] + '/' + image_row['accession_number'] + '.json_1',\n",
    "            'selector': {\n",
    "                'type': 'oa:FragmentSelector',\n",
    "                'value': fragment_selector\n",
    "            },\n",
    "            'within': {\n",
    "                '@id': 'https://iiif-manifest.library.vanderbilt.edu/gallery/' + image_row['accession_number'].split('.')[0] + '/' + image_row['accession_number'] + '.json',\n",
    "                '@type': 'sc:Manifest'\n",
    "            }\n",
    "        }\n",
    "        resource_value = {\n",
    "            '@type': 'dctypes:Text',\n",
    "            'format': 'text/plain',\n",
    "            'chars': object_row['description']\n",
    "        }\n",
    "\n",
    "        annotation = {\n",
    "            '@context': 'http://iiif.io/api/presentation/2/context.json',\n",
    "            '@id': 'https://iiif-manifest.library.vanderbilt.edu/gallery/' + image_row['accession_number'].split('.')[0] + '/' + image_row['accession_number'] + '/annotation/' + str(object_index),\n",
    "            '@type': 'oa:Annotation',\n",
    "            'motivation': [\n",
    "                'oa:commenting'\n",
    "            ],\n",
    "            'on': on_value,\n",
    "            'resource': [\n",
    "                resource_value\n",
    "            ]\n",
    "        }\n",
    "        resources.append(annotation)\n",
    "    \n",
    "    annotations = {\n",
    "        \"@context\": \"http://www.shared-canvas.org/ns/context.json\",\n",
    "        \"@id\": annotations_base_url + image_row['accession_number'].split('.')[0] + \"/\" + image_row['accession_number'] + \"_annotations.json\",\n",
    "        \"@type\": \"sc:AnnotationList\",\n",
    "        \"resources\": resources\n",
    "    }\n",
    "\n",
    "    # Write the annotations to a JSON file.\n",
    "    with open(base_path + 'annotations/' + image_row['accession_number'] + '_annotations.json', 'w') as outfile:\n",
    "        output_text = json.dumps(annotations, indent=2)\n",
    "        outfile.write(output_text)\n",
    "\n",
    "print('done')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the link from the manifest to the annotation URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956.012\n",
      "1956.043\n",
      "1971.002\n",
      "1979.0016\n",
      "1979.0071\n",
      "1979.0190P\n",
      "1979.0236P\n",
      "1979.0238P\n",
      "1979.0243P\n",
      "1979.0249P\n",
      "1979.0282P\n",
      "1979.0322P\n",
      "1979.0524P\n",
      "1979.0553\n",
      "1979.0634P\n",
      "1979.0721P\n",
      "1979.0840P\n",
      "1979.1178P\n",
      "1979.1216P\n",
      "1979.1225P\n",
      "1979.1232P\n",
      "1980.037\n",
      "1986.054\n",
      "1992.114\n",
      "1995.010\n",
      "2002.009\n",
      "2003.036\n",
      "2017.001.058\n",
      "2018.002\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Step through each image in the accession dimensions CSV file.\n",
    "for image_index, image_row in accession_dataframe.iterrows():\n",
    "    print(image_row['accession_number'])\n",
    "\n",
    "    # Look up the manifest URL for the image in the source image dataframe.\n",
    "    manifest_url = source_image_dataframe.loc[source_image_dataframe['accession_number'] == image_row['accession_number'], 'iiif_manifest'].iloc[0]\n",
    "    \n",
    "    # Get the manifest JSON.\n",
    "    manifest_response = requests.get(manifest_url)\n",
    "    manifest_json = manifest_response.json()\n",
    "    \n",
    "    # Create otherContent dictionary.\n",
    "    other_content = [\n",
    "        {\n",
    "        '@id': annotations_base_url + image_row['accession_number'].split('.')[0] + \"/\" + image_row['accession_number'] + \"_annotations.json\",\n",
    "        '@type': 'sc:AnnotationList'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Add the otherContent dictionary to the manifest.\n",
    "    manifest_json['sequences'][0]['canvases'][0]['otherContent'] = other_content\n",
    "\n",
    "    # Write the manifest to a JSON file.\n",
    "    with open(base_path + 'manifests/' + image_row['accession_number'] + '.json', 'w') as outfile:\n",
    "        text = json.dumps(manifest_json, indent=4)\n",
    "        outfile.write(text)\n",
    "\n",
    "print('done')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f96c65e2c1d4fcba82e9525c1be2fd15c6a14102f9c31bd3457b5f48c526190"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
