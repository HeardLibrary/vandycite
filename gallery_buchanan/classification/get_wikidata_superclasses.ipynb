{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparqler, a class for make SPARQL queries to the Wikidata Query Service and other endpoints.\n",
    "version = '1.1'\n",
    "created = '2023-02-12'\n",
    "\n",
    "# (c) 2022-2023 Steven J. Baskauf\n",
    "# This program is released under a GNU General Public License v3.0 http://www.gnu.org/licenses/gpl-3.0\n",
    "# Author: Steve Baskauf\n",
    "\n",
    "# -----------------------------------------\n",
    "# Version 1.0 change notes (2022-06-07):\n",
    "# - Initial version\n",
    "# -----------------------------------------\n",
    "# Version 1.1 change notes (2023-02-12):\n",
    "# - Added support for sessions\n",
    "# -----------------------------------------\n",
    "\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "class Sparqler:\n",
    "    \"\"\"Build SPARQL queries of various sorts\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    method: str\n",
    "        Possible values are \"post\" (default) or \"get\". Use \"get\" if read-only query endpoint.\n",
    "        Must be \"post\" for update endpoint.\n",
    "    endpoint: URL\n",
    "        Defaults to Wikidata Query Service if not provided.\n",
    "    useragent : str\n",
    "        Required if using the Wikidata Query Service, otherwise optional.\n",
    "        Use the form: appname/v.v (URL; mailto:email@domain.com)\n",
    "        See https://meta.wikimedia.org/wiki/User-Agent_policy\n",
    "    session: requests.Session\n",
    "        If provided, the session will be used for all queries. Note: required for the Commons Query Service.\n",
    "        If not provided, a generic requests method (get or post) will be used.\n",
    "        NOTE: Currently only implemented for the .query() method since I don't have any way to test the mehtods that write.\n",
    "    sleep: float\n",
    "        Number of seconds to wait between queries. Defaults to 0.1\n",
    "        \n",
    "    Required modules:\n",
    "    -------------\n",
    "    requests, datetime, time\n",
    "    \"\"\"\n",
    "    def __init__(self, method='post', endpoint='https://query.wikidata.org/sparql', useragent=None, session=None, sleep=0.1):\n",
    "        # attributes for all methods\n",
    "        self.http_method = method\n",
    "        self.endpoint = endpoint\n",
    "        if useragent is None:\n",
    "            if self.endpoint == 'https://query.wikidata.org/sparql':\n",
    "                print('You must provide a value for the useragent argument when using the Wikidata Query Service.')\n",
    "                print()\n",
    "                raise KeyboardInterrupt # Use keyboard interrupt instead of sys.exit() because it works in Jupyter notebooks\n",
    "        self.session = session\n",
    "        self.sleep = sleep\n",
    "\n",
    "        self.requestheader = {}\n",
    "        if useragent:\n",
    "            self.requestheader['User-Agent'] = useragent\n",
    "        \n",
    "        if self.http_method == 'post':\n",
    "            self.requestheader['Content-Type'] = 'application/x-www-form-urlencoded'\n",
    "\n",
    "    def query(self, query_string, form='select', verbose=False, **kwargs):\n",
    "        \"\"\"Sends a SPARQL query to the endpoint.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        form : str\n",
    "            The SPARQL query form.\n",
    "            Possible values are: \"select\" (default), \"ask\", \"construct\", and \"describe\".\n",
    "        mediatype: str\n",
    "            The response media type (MIME type) of the query results.\n",
    "            Some possible values for \"select\" and \"ask\" are: \"application/sparql-results+json\" (default) and \"application/sparql-results+xml\".\n",
    "            Some possible values for \"construct\" and \"describe\" are: \"text/turtle\" (default) and \"application/rdf+xml\".\n",
    "            See https://docs.aws.amazon.com/neptune/latest/userguide/sparql-media-type-support.html#sparql-serialization-formats-neptune-output\n",
    "            for response serializations supported by Neptune.\n",
    "        verbose: bool\n",
    "            Prints status when True. Defaults to False.\n",
    "        default: list of str\n",
    "            The graphs to be merged to form the default graph. List items must be URIs in string form.\n",
    "            If omitted, no graphs will be specified and default graph composition will be controlled by FROM clauses\n",
    "            in the query itself. \n",
    "            See https://www.w3.org/TR/sparql11-query/#namedGraphs and https://www.w3.org/TR/sparql11-protocol/#dataset\n",
    "            for details.\n",
    "        named: list of str\n",
    "            Graphs that may be specified by IRI in a query. List items must be URIs in string form.\n",
    "            If omitted, named graphs will be specified by FROM NAMED clauses in the query itself.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        If the form is \"select\" and mediatype is \"application/json\", a list of dictionaries containing the data.\n",
    "        If the form is \"ask\" and mediatype is \"application/json\", a boolean is returned.\n",
    "        If the mediatype is \"application/json\" and an error occurs, None is returned.\n",
    "        For other forms and mediatypes, the raw output is returned.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        To get UTF-8 text in the SPARQL queries to work properly, send URL-encoded text rather than raw text.\n",
    "        That is done automatically by the requests module for GET. I guess it also does it for POST when the\n",
    "        data are sent as a dict with the urlencoded header. \n",
    "        See SPARQL 1.1 protocol notes at https://www.w3.org/TR/sparql11-protocol/#query-operation        \n",
    "        \"\"\"\n",
    "        query_form = form\n",
    "        if 'mediatype' in kwargs:\n",
    "            media_type = kwargs['mediatype']\n",
    "        else:\n",
    "            if query_form == 'construct' or query_form == 'describe':\n",
    "            #if query_form == 'construct':\n",
    "                media_type = 'text/turtle'\n",
    "            else:\n",
    "                media_type = 'application/sparql-results+json' # default for SELECT and ASK query forms\n",
    "        self.requestheader['Accept'] = media_type\n",
    "            \n",
    "        # Build the payload dictionary (query and graph data) to be sent to the endpoint\n",
    "        payload = {'query' : query_string}\n",
    "        if 'default' in kwargs:\n",
    "            payload['default-graph-uri'] = kwargs['default']\n",
    "        \n",
    "        if 'named' in kwargs:\n",
    "            payload['named-graph-uri'] = kwargs['named']\n",
    "\n",
    "        if verbose:\n",
    "            print('querying SPARQL endpoint')\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "        if self.http_method == 'post':\n",
    "            if self.session is None:\n",
    "                response = requests.post(self.endpoint, data=payload, headers=self.requestheader)\n",
    "            else:\n",
    "                response = self.session.post(self.endpoint, data=payload, headers=self.requestheader)\n",
    "        else:\n",
    "            if self.session is None:\n",
    "                response = requests.get(self.endpoint, params=payload, headers=self.requestheader)\n",
    "            else:\n",
    "                response = self.session.get(self.endpoint, params=payload, headers=self.requestheader)\n",
    "        elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "        self.response = response.text\n",
    "        time.sleep(self.sleep) # Throttle as a courtesy to avoid hitting the endpoint too fast.\n",
    "\n",
    "        if verbose:\n",
    "            print('done retrieving data in', int(elapsed_time), 's')\n",
    "\n",
    "        if query_form == 'construct' or query_form == 'describe':\n",
    "            return response.text\n",
    "        else:\n",
    "            if media_type != 'application/sparql-results+json':\n",
    "                return response.text\n",
    "            else:\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                except:\n",
    "                    return None # Returns no value if an error. \n",
    "\n",
    "                if query_form == 'select':\n",
    "                    # Extract the values from the response JSON\n",
    "                    results = data['results']['bindings']\n",
    "                else:\n",
    "                    results = data['boolean'] # True or False result from ASK query \n",
    "                return results           \n",
    "\n",
    "    def update(self, request_string, mediatype='application/json', verbose=False, **kwargs):\n",
    "        \"\"\"Sends a SPARQL update to the endpoint.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        mediatype : str\n",
    "            The response media type (MIME type) from the endpoint after the update.\n",
    "            Default is \"application/json\"; probably no need to use anything different.\n",
    "        verbose: bool\n",
    "            Prints status when True. Defaults to False.\n",
    "        default: list of str\n",
    "            The graphs to be merged to form the default graph. List items must be URIs in string form.\n",
    "            If omitted, no graphs will be specified and default graph composition will be controlled by USING\n",
    "            clauses in the query itself. \n",
    "            See https://www.w3.org/TR/sparql11-update/#deleteInsert\n",
    "            and https://www.w3.org/TR/sparql11-protocol/#update-operation for details.\n",
    "        named: list of str\n",
    "            Graphs that may be specified by IRI in the graph pattern. List items must be URIs in string form.\n",
    "            If omitted, named graphs will be specified by USING NAMED clauses in the query itself.\n",
    "        \"\"\"\n",
    "        media_type = mediatype\n",
    "        self.requestheader['Accept'] = media_type\n",
    "        \n",
    "        # Build the payload dictionary (update request and graph data) to be sent to the endpoint\n",
    "        payload = {'update' : request_string}\n",
    "        if 'default' in kwargs:\n",
    "            payload['using-graph-uri'] = kwargs['default']\n",
    "        \n",
    "        if 'named' in kwargs:\n",
    "            payload['using-named-graph-uri'] = kwargs['named']\n",
    "\n",
    "        if verbose:\n",
    "            print('beginning update')\n",
    "            \n",
    "        start_time = datetime.datetime.now()\n",
    "        response = requests.post(self.endpoint, data=payload, headers=self.requestheader)\n",
    "        elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "        self.response = response.text\n",
    "        time.sleep(self.sleep) # Throttle as a courtesy to avoid hitting the endpoint too fast.\n",
    "\n",
    "        if verbose:\n",
    "            print('done updating data in', int(elapsed_time), 's')\n",
    "\n",
    "        if media_type != 'application/json':\n",
    "            return response.text\n",
    "        else:\n",
    "            try:\n",
    "                data = response.json()\n",
    "            except:\n",
    "                return None # Returns no value if an error converting to JSON (e.g. plain text) \n",
    "            return data           \n",
    "\n",
    "    def load(self, file_location, graph_uri, s3='', verbose=False, **kwargs):\n",
    "        \"\"\"Loads an RDF document into a specified graph.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        s3 : str\n",
    "            Name of an AWS S3 bucket containing the file. Omit load a generic URL.\n",
    "        verbose: bool\n",
    "            Prints status when True. Defaults to False.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        The triplestore may or may not rely on receiving a correct Content-Type header with the file to\n",
    "        determine the type of serialization. Blazegraph requires it, AWS Neptune does not and apparently\n",
    "        interprets serialization based on the file extension.\n",
    "        \"\"\"\n",
    "        if s3:\n",
    "            request_string = 'LOAD <https://' + s3 + '.s3.amazonaws.com/' + file_location + '> INTO GRAPH <' + graph_uri + '>'\n",
    "        else:\n",
    "            request_string = 'LOAD <' + file_location + '> INTO GRAPH <' + graph_uri + '>'\n",
    "        \n",
    "        if verbose:\n",
    "            print('Loading file:', file_location, ' into graph: ', graph_uri)\n",
    "        data = self.update(request_string, verbose=verbose)\n",
    "        return data\n",
    "\n",
    "    def drop(self, graph_uri, verbose=False, **kwargs):\n",
    "        \"\"\"Drop a specified graph.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        verbose: bool\n",
    "            Prints status when True. Defaults to False.\n",
    "        \"\"\"\n",
    "        request_string = 'DROP GRAPH <' + graph_uri + '>'\n",
    "\n",
    "        if verbose:\n",
    "            print('Deleting graph:', graph_uri)\n",
    "        data = self.update(request_string, verbose=verbose)\n",
    "        return data\n",
    "\n",
    "# -----------------\n",
    "# Body of script\n",
    "# -----------------\n",
    "\n",
    "# Instantiate the Sparqler class\n",
    "user_agent = 'SuperClassDownloader/0.1 (mailto:steve.baskauf@vanderbilt.edu)'\n",
    "wdqs = Sparqler(useragent=user_agent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the superclass links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = '''construct {\n",
    "  ?class wdt:P279 ?superclass.\n",
    "  ?base_class rdfs:label ?base_label.\n",
    "  ?superclass rdfs:label ?super_label.\n",
    "  }\n",
    "where {\n",
    "  # Q102971873 is \"Soba-choko (noodle sauce cup) with a design in blue underglaze of a stylized rock and grasses\"\n",
    "  #bind (wd:Q102971873 as ?artwork) # Comment out this line to do all artworks\n",
    "  ?artwork wdt:P195 wd:Q18563658. # must be in the Vanderbilt Art Gallery\n",
    "  ?artwork wdt:P31 ?base_class. # artwork is an instance of the base class\n",
    "  ?base_class wdt:P279* ?class. # the subject class is 0 to many subclass_of links from the base class\n",
    "  ?class wdt:P279 ?superclass. # the class must have a superclass\n",
    "  \n",
    "  ?base_class rdfs:label ?base_label.\n",
    "  filter(lang(?base_label)=\"en\")\n",
    "  ?superclass rdfs:label ?super_label.\n",
    "  filter(lang(?super_label)=\"en\")\n",
    "  }\n",
    "'''\n",
    "#print(query)\n",
    "\n",
    "data = wdqs.query(query_string, form='construct')\n",
    "if data is None:\n",
    "    print(\"Error\")\n",
    "else:\n",
    "    pass\n",
    "    #print(data)\n",
    "#print(wdqs.response)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the text to a file\n",
    "filename = 'superclasses.ttl'\n",
    "with open (filename, 'w') as output_file:\n",
    "    output_file.write(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the links from works to their base classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = '''construct {\n",
    "  ?artwork wdt:P31 ?class.\n",
    "  ?artwork rdfs:label ?label.\n",
    "  }\n",
    "where {\n",
    "  ?artwork wdt:P195 wd:Q18563658.\n",
    "  ?artwork wdt:P31 ?class.\n",
    "  ?artwork rdfs:label ?label.\n",
    "  filter(lang(?label)=\"en\")\n",
    "  }\n",
    "'''\n",
    "#print(query)\n",
    "\n",
    "\n",
    "data = wdqs.query(query_string, form='construct')\n",
    "if data is None:\n",
    "    print(\"Error\")\n",
    "else:\n",
    "    print(data)\n",
    "#print(wdqs.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the text to a file\n",
    "filename = 'works_class_links.ttl'\n",
    "with open (filename, 'w') as output_file:\n",
    "    output_file.write(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
