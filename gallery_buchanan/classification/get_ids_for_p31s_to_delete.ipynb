{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will get the Q IDs for the gallery works whose P31 values are going to be changed after the reclassification/hierarchy project. Those Q IDs will then have their claims pulled from the CSV where they were saved after the original upload.\n",
    "\n",
    "NOTE: The upload file doesn't capture any references for the new P31 values. They need to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "uuid_for_claim_to_delete_column_name = 'instance_of'\n",
    "\n",
    "def write_dicts_to_csv(table, filename, fieldnames):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csv_file_object:\n",
    "        writer = csv.DictWriter(csv_file_object, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "\n",
    "works_to_change_frame = pd.read_csv('3d_parts.csv', na_filter=False, dtype = str)\n",
    "#works_to_change_frame = works_to_change_frame.head(3).copy() # uncomment for testing\n",
    "thesaurus_ids_frame = pd.read_csv('thesauri_ids.csv', na_filter=False, dtype = str)\n",
    "works_original_data_frame = pd.read_csv('../../gallery_works/works_multiprop.csv', na_filter=False, dtype = str)\n",
    "\n",
    "noun_list = list(set(thesaurus_ids_frame['noun'])) # create a non-redundant list of the nouns used\n",
    "works_qid_list = list(set(works_original_data_frame['qid']))\n",
    "\n",
    "# Set up lists to hold the output data\n",
    "claims_to_delete_list = []\n",
    "claims_to_add_list = []\n",
    "\n",
    "# Step through each item for which the new P31 claim needs to be made\n",
    "for index, claim_row in works_to_change_frame.iterrows():\n",
    "    qid = claim_row['qid']\n",
    "    print(qid)\n",
    "    # Look up the descriptive noun in the theaurus ID crosswalk and get the Wikidata Q ID for it\n",
    "    if claim_row['noun-modified'] in noun_list:\n",
    "        # Note, there should not be more than one matching result, hence .values[0]\n",
    "        class_qid = thesaurus_ids_frame.loc[thesaurus_ids_frame.noun == claim_row['noun-modified'], 'wikidata'].values[0]\n",
    "    else:\n",
    "        print('Could not find a class Q ID for work', qid, 'with noun', claim_row['noun-modified'], ', index:', index)\n",
    "        continue # Skip doing this row since the value couldn't be found\n",
    "        \n",
    "    # Look up the UUID for the current P31 claim\n",
    "    if qid in works_qid_list:\n",
    "        uuid = works_original_data_frame.loc[works_original_data_frame.qid == qid, uuid_for_claim_to_delete_column_name + '_uuid'].values[0]\n",
    "        old_p31_qid = works_original_data_frame.loc[works_original_data_frame.qid == qid, uuid_for_claim_to_delete_column_name].values[0]\n",
    "    else:\n",
    "        print('Could not find a claim UUID for work', qid, ', index:', index)\n",
    "        continue\n",
    "    claims_to_delete_list.append({'qid': qid, uuid_for_claim_to_delete_column_name + '_uuid': uuid, uuid_for_claim_to_delete_column_name: old_p31_qid})\n",
    "    claims_to_add_list.append({'qid': qid, uuid_for_claim_to_delete_column_name + '_uuid': '', uuid_for_claim_to_delete_column_name: class_qid})\n",
    "    \n",
    "fieldnames = ['qid', uuid_for_claim_to_delete_column_name + '_uuid', uuid_for_claim_to_delete_column_name]\n",
    "write_dicts_to_csv(claims_to_delete_list, 'test_delete.csv', fieldnames)\n",
    "write_dicts_to_csv(claims_to_add_list, 'test_upload.csv', fieldnames)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the new P31 claims, I wanted to re-assert the same references as before. It would have been better to just have done that at the time of creating the new claims, but it seems easier to just replace the new P31 values and claim UUIDs in the master data table and then re-write the references that were there before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "uuid_for_claim_to_delete_column_name = 'instance_of'\n",
    "\n",
    "works_original_data_frame = pd.read_csv('../../gallery_works/works_multiprop.csv', na_filter=False, dtype = str)\n",
    "#works_original_data_frame = works_original_data_frame.head(5).copy() # uncomment for testing\n",
    "new_p31_claims_frame = pd.read_csv('test_upload.csv', na_filter=False, dtype = str)\n",
    "qid_list = list(set(new_p31_claims_frame['qid'])) # create a non-redundant list of the qids of changed P31s\n",
    "\n",
    "for index, work_row in works_original_data_frame.iterrows():\n",
    "    print(work_row['qid'])\n",
    "    if work_row['qid'] in qid_list: # Only change rows whose Q IDs are in the table of changed values\n",
    "        # Transfer the new UUIDs and P31 values from the table of changed values\n",
    "        work_row[uuid_for_claim_to_delete_column_name + '_uuid'] = new_p31_claims_frame.loc[new_p31_claims_frame.qid == work_row['qid'], uuid_for_claim_to_delete_column_name + '_uuid'].values[0]\n",
    "        work_row[uuid_for_claim_to_delete_column_name] = new_p31_claims_frame.loc[new_p31_claims_frame.qid == work_row['qid'], uuid_for_claim_to_delete_column_name].values[0]\n",
    "        # Set the value of the reference hash to empty string so that the references will be added to the claims.\n",
    "        work_row[uuid_for_claim_to_delete_column_name + '_ref1_hash'] = ''\n",
    "        \n",
    "works_original_data_frame.to_csv('../../gallery_works/works_multiprop.csv', index = False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
