{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration and functions\n",
    "\n",
    "Run for every cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Pandas for data frame management\n",
    "import pandas as pd\n",
    "\n",
    "# Natural Language Tool Kit\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import RegexpParser\n",
    "\n",
    "# Language detection\n",
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "\n",
    "# ---------------\n",
    "# Utility functions\n",
    "# ---------------\n",
    "\n",
    "# read from a CSV file into a list of dictionaries\n",
    "def read_dict(filename):\n",
    "    with open(filename, 'r', newline='', encoding='utf-8') as file_object:\n",
    "        dict_object = csv.DictReader(file_object)\n",
    "        array = []\n",
    "        for row in dict_object:\n",
    "            array.append(row)\n",
    "    return array\n",
    "\n",
    "# write a list of dictionaries to a CSV file\n",
    "def write_dicts_to_csv(table, filename, fieldnames):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csv_file_object:\n",
    "        writer = csv.DictWriter(csv_file_object, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "# ---------------\n",
    "# Processing functions\n",
    "# ---------------\n",
    "\n",
    "# This function splits a string based on finding the test_string in it and returns info on the pieces\n",
    "def test_split(target_string, test_string):\n",
    "    split = False\n",
    "    pieces = target_string.split(test_string)\n",
    "    # remove leading and trailing spaces\n",
    "    for piece_number in range(len(pieces)):\n",
    "        pieces[piece_number] = pieces[piece_number].strip()\n",
    "    if len(pieces) != 1:\n",
    "        split = True\n",
    "    return split, len(pieces), pieces\n",
    "\n",
    "# Test all possible splitting strings and return information about whether the target_string was split\n",
    "def split_string(target_string, test_string_list):\n",
    "    for test_string in test_string_list:\n",
    "        split, n_pieces, pieces = test_split(target_string, test_string)\n",
    "        if split: # quit the function if a particular test string worked\n",
    "            return split, n_pieces, pieces\n",
    "    # If none of the test strings worked, then return false and the original string\n",
    "    return False, 1, target_string\n",
    "\n",
    "def detect_language(string):\n",
    "    try:\n",
    "        lang_list = detect_langs(string)\n",
    "        lang_string = str(lang_list[0])\n",
    "        confidence = float(lang_string[3:])\n",
    "        lang = lang_string[:2]\n",
    "    except: #exceptions occur when no info to decide, e.g. numbers\n",
    "        lang = 'zxx'\n",
    "        confidence = float(0)\n",
    "    return lang, confidence\n",
    "\n",
    "precision_cutoff = 0.5\n",
    "phrase_length_cutoff = 2\n",
    "def words_in_phrase(piece):\n",
    "    tokens = nltk.word_tokenize(piece)\n",
    "    if '.' in tokens:\n",
    "        tokens.remove('.')\n",
    "    if 's' in tokens:\n",
    "        tokens.remove('s')\n",
    "    if '’' in tokens:\n",
    "        tokens.remove('’')\n",
    "    return len(tokens)\n",
    "\n",
    "def treat_as_single_string(pieces):\n",
    "    abort = False\n",
    "    lang_list = []\n",
    "    for piece in pieces:\n",
    "        lang, prec = detect_language(piece.strip())\n",
    "        lang_list.append(lang)\n",
    "        if prec < precision_cutoff:\n",
    "            abort = True\n",
    "            #print('fail precision cutoff')\n",
    "        if words_in_phrase(piece) <= phrase_length_cutoff:\n",
    "            abort = True\n",
    "            #print('fail word length cutoff')\n",
    "            \n",
    "    if lang_list[0] == lang_list[1]:\n",
    "        abort = True\n",
    "        #print('fail same language test')\n",
    "    return abort\n",
    "\n",
    "def generate_translations(label):\n",
    "    translations_list = [] # Create a list to hold the translations\n",
    "\n",
    "    # Split the phrase to pull out anything in a first set of parentheses\n",
    "    pieces = label.split('(') # Split label into parts before and after left parenthesis\n",
    "    if len(pieces) > 2:\n",
    "        pieces = list(pieces[:2]) # Throw away anything after a second set of parentheses (limit to first parentheses only)    \n",
    "    \n",
    "    # Code to decide whether parenthetical text is a translation\n",
    "    if len(pieces) == 2: # Don't analyze if no parentheses\n",
    "        pieces[1] = pieces[1].split(')')[0] # Remove anything after the right parenthesis for the parenthetical phrase\n",
    "        if treat_as_single_string(pieces):\n",
    "            pieces = [label] # If it fails the translations screening test, treat it as a single string\n",
    "        \n",
    "    for piece in pieces:\n",
    "        translation_data = {'text': piece.strip()} # Create a dict to hold translation data\n",
    "        translation_data['n_words'] = words_in_phrase(piece)\n",
    "        lang, prec = detect_language(piece)\n",
    "        translation_data['language'] = lang\n",
    "        translation_data['probability'] = prec\n",
    "        \n",
    "        translations_list.append(translation_data)\n",
    "        #print()\n",
    "    return translations_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 3D works to determine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = pd.read_csv('works_classification.csv', na_filter=False, dtype = str)\n",
    "works = pd.read_csv('works_multiprop.csv', na_filter=False, dtype = str)\n",
    "#test = works.head(100)\n",
    "\n",
    "output_list_3d = []\n",
    "\n",
    "# Iterate through the work rows to analize label text\n",
    "for index, work in works.iterrows():\n",
    "    # Look up the dimension and type info for the work from the classifications DataFrame\n",
    "    dimension = classifications.loc[classifications.qid==work['qid'], 'dimension'].values[0]\n",
    "    type = classifications.loc[classifications.qid==work['qid'], 'type'].values[0]\n",
    "\n",
    "    #print(work['label_en'], dimension, type)\n",
    "    if dimension == '3D':\n",
    "        label = work['label_en']\n",
    "        print(label)\n",
    "        work_dict = {'qid': work['qid'], 'type': type, 'label': label}\n",
    "        processed = False\n",
    "        \n",
    "        # Test \"with a Design/design\"\n",
    "        test_string_list = ['with a Design', 'with a design', 'with designs', 'with design', 'With a Design', 'With Design', 'depicting']\n",
    "        split, n_pieces, pieces = split_string(label, test_string_list)\n",
    "        if split:\n",
    "            processed = True\n",
    "            if n_pieces > 2:\n",
    "                pieces = list(pieces[:2]) # limit to two parts, not likely to ever happen with this one\n",
    "                work_dict['object_description'] = 'Error on \"with a Design\"'\n",
    "            if n_pieces == 2:\n",
    "                work_dict['object_description'] = pieces[0]\n",
    "                work_dict['form_description'] = ''\n",
    "                work_dict['design_description'] = pieces[1]\n",
    "                work_dict['includes'] = ''\n",
    "        \n",
    "        # Test \"in the form of/Form of\"\n",
    "        if not processed: # do not perform the test if a previous split already worked\n",
    "            test_string_list = ['in the Form of', 'in the form of', 'in the shape of', 'in the design of', 'in the Shape of', 'Representing']\n",
    "            split, n_pieces, pieces = split_string(label, test_string_list)\n",
    "            if split:\n",
    "                processed = True\n",
    "                if len(pieces) > 2:\n",
    "                    pieces = list(pieces[:2]) # limit to two parts, not likely to ever happen with this one\n",
    "                    work_dict['object_description'] = 'Error on \"in the form of\"'\n",
    "                if len(pieces) == 2:\n",
    "                    work_dict['object_description'] = pieces[0]\n",
    "                    work_dict['form_description'] = pieces[1]\n",
    "                    work_dict['design_description'] = ''\n",
    "                    work_dict['includes'] = ''\n",
    "\n",
    "        # Test \"with\"\n",
    "        if not processed: # do not perform the test if a previous split already worked\n",
    "            test_string_list = ['with', 'With']\n",
    "            split, n_pieces, pieces = split_string(label, test_string_list)\n",
    "            if split:\n",
    "                processed = True\n",
    "                # if there are more than two \"with\"s in the string, only split by the first one\n",
    "                if len(pieces) > 2:\n",
    "                    # re-assemble phrase after first \"with\"\n",
    "                    built = pieces[1]\n",
    "                    for piece in pieces[2:]:\n",
    "                        built += ' with ' + piece\n",
    "                    pieces = [pieces[0], built]\n",
    "\n",
    "                work_dict['object_description'] = pieces[0]\n",
    "                work_dict['form_description'] = ''\n",
    "                work_dict['design_description'] = ''\n",
    "                work_dict['includes'] = pieces[1]\n",
    "\n",
    "        # If none of the splits worked, just leave the label as the object description\n",
    "        if not processed:\n",
    "            work_dict['object_description'] = label\n",
    "            work_dict['form_description'] = ''\n",
    "            work_dict['design_description'] = ''\n",
    "            work_dict['includes'] = ''\n",
    "\n",
    "        #print(json.dumps(work_dict, indent = 2))\n",
    "        #print()\n",
    "        \n",
    "        output_list_3d.append(work_dict)\n",
    "\n",
    "with open('3d_parts.json', 'wt', encoding='utf-8') as fileObject:\n",
    "    fileObject.write(json.dumps(output_list_3d, indent = 2))\n",
    "    \n",
    "fieldnames = list(output_list_3d[0].keys())\n",
    "write_dicts_to_csv(output_list_3d, '3d_parts.csv', fieldnames)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process titles for language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = pd.read_csv('works_multiprop.csv', na_filter=False, dtype = str)\n",
    "# limit to rows that are missing titles and get only the qid and label columns\n",
    "no_titles = works.loc[works.title=='', 'qid': 'label_en'].copy()\n",
    "\n",
    "output_list = []\n",
    "for index, work in no_titles.iterrows():\n",
    "    print(work['label_en'])\n",
    "    translations = generate_translations(work['label_en'])\n",
    "    line_dict = {'qid': work['qid'], 'label': work['label_en']}\n",
    "    n = 0\n",
    "    for language in translations:\n",
    "        n += 1\n",
    "        line_dict['title' + str(n)] = language['text']\n",
    "        line_dict['language' + str(n)] = language['language']\n",
    "        line_dict['probability' + str(n)] = language['probability']\n",
    "    if n == 1:\n",
    "        line_dict['title2'] = ''\n",
    "        line_dict['language2'] = ''\n",
    "        line_dict['probability2'] = 0\n",
    "    output_list.append(line_dict)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames = list(output_list[0].keys())\n",
    "write_dicts_to_csv(output_list, 'titles_lang.csv', fieldnames)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = read_dict('works_classification.csv')\n",
    "works = read_dict('works_multiprop.csv')\n",
    "#print(classifications[0:2])\n",
    "#print()\n",
    "#print(works[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = []\n",
    "for work in works:\n",
    "    for classification in classifications:\n",
    "        found = False\n",
    "        if work['qid'] == classification['qid']:\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        #print(work['label_en'], classification['dimension'], classification['type'])\n",
    "        if classification['dimension'] == '3D':\n",
    "            label = work['label_en']\n",
    "            print(label)\n",
    "            work_dict = {'qid': work['qid'], 'type': classification['type'], 'label': label}\n",
    "            \n",
    "            processed = False\n",
    "            \n",
    "            # -------------\n",
    "            # with a Design/design\n",
    "            # -------------\n",
    "\n",
    "            # Split the phrase by object description and design on object\n",
    "            split = False\n",
    "            pieces = label.split('with a Design')\n",
    "            if len(pieces) != 1:\n",
    "                split = True\n",
    "            else:\n",
    "                pieces = label.split('with a design')\n",
    "                if len(pieces) != 1:\n",
    "                    split = True\n",
    "                else:\n",
    "                    pieces = label.split('with designs')\n",
    "                    if len(pieces) != 1:\n",
    "                        split = True\n",
    "                    else:\n",
    "                        pieces = label.split('with design')\n",
    "                        if len(pieces) != 1:\n",
    "                            split = True\n",
    "\n",
    "            if split:\n",
    "                processed = True\n",
    "                if len(pieces) > 2:\n",
    "                    pieces = list(pieces[:2]) # limit to two parts, not likely to ever happen with this one\n",
    "                    print('Error on \"with a Design\"')\n",
    "                if len(pieces) == 2:\n",
    "                    work_dict['object_description'] = generate_translations(pieces[0].strip())\n",
    "                    work_dict['form_description'] = ''\n",
    "                    work_dict['design_description'] = generate_translations(pieces[1].strip())\n",
    "                    work_dict['includes'] = ''\n",
    "\n",
    "            # -------------\n",
    "            # in the form of/Form of\n",
    "            # -------------\n",
    "\n",
    "            # Split the phrase by object description and design on object\n",
    "            split = False\n",
    "            pieces = label.split('in the Form of')\n",
    "            if len(pieces) != 1:\n",
    "                split = True\n",
    "            else:\n",
    "                pieces = label.split('in the form of')\n",
    "                if len(pieces) != 1:\n",
    "                    split = True\n",
    "\n",
    "            if split:\n",
    "                processed = True\n",
    "                if len(pieces) > 2:\n",
    "                    pieces = list(pieces[:2]) # limit to two parts, not likely to ever happen with this one\n",
    "                    print('Error on \"in the form of\"')\n",
    "                #print(pieces)\n",
    "                if len(pieces) == 2:\n",
    "                    work_dict['object_description'] = generate_translations(pieces[0].strip())\n",
    "                    work_dict['form_description'] = generate_translations(pieces[1].strip())\n",
    "                    work_dict['design_description'] = ''\n",
    "                    work_dict['includes'] = ''\n",
    "            \n",
    "            if not processed:\n",
    "                pieces = label.split('with')\n",
    "                if len(pieces) != 1:\n",
    "                    split = True\n",
    "                else:\n",
    "                    pieces = label.split('With')\n",
    "                    if len(pieces) != 1:\n",
    "                        split = True\n",
    "                        \n",
    "                if split:\n",
    "                    processed = True\n",
    "                    if len(pieces) > 2:\n",
    "                        # re-assemble phrase after first \"with\"\n",
    "                        built = pieces[1]\n",
    "                        for piece in pieces[2:]:\n",
    "                            built += 'with' + piece\n",
    "                        pieces = [pieces[0], built]\n",
    "\n",
    "                    work_dict['object_description'] = generate_translations(pieces[0].strip())\n",
    "                    work_dict['form_description'] = ''\n",
    "                    work_dict['design_description'] = ''\n",
    "                    work_dict['includes'] = generate_translations(pieces[1].strip())\n",
    "\n",
    "            if not processed:\n",
    "                work_dict['object_description'] = generate_translations(label)\n",
    "                work_dict['form_description'] = ''\n",
    "                work_dict['design_description'] = ''\n",
    "                work_dict['includes'] = ''\n",
    "\n",
    "            output_list.append(work_dict)\n",
    "\n",
    "'''\n",
    "with open('2d_parts.json', 'wt', encoding='utf-8') as fileObject:\n",
    "    # If analysis occurrred successfully, update the last_run date in the file with today's date\n",
    "    fileObject.write(json.dumps(output_list, indent = 2))\n",
    "''' \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
