{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commonsbot.ipynb, a Python script for uploading files and data to Wikimedia Commons using the API.\n",
    "\n",
    "# (c) 2022 Vanderbilt University. This program is released under a GNU General Public License v3.0 http://www.gnu.org/licenses/gpl-3.0\n",
    "# Author: Steve Baskauf\n",
    "\n",
    "# ----------------\n",
    "# Global variables\n",
    "# ----------------\n",
    "\n",
    "script_version = '0.5.1'\n",
    "version_modified = '2022-08-24'\n",
    "commons_prefix = 'http://commons.wikimedia.org/wiki/Special:FilePath/'\n",
    "commons_page_prefix = 'https://commons.wikimedia.org/wiki/File:'\n",
    "\n",
    "# -----------------------------------------\n",
    "# Version 0.4 change notes: \n",
    "# - Removed double spaces from labels before they are used to generate image filenames.\n",
    "# - Skip over images with raw filenames that contain spaces and log an error for them to be manually removed.\n",
    "# -----------------------------------------\n",
    "# Version 0.5.1 change notes:\n",
    "# - enable writing of multiple Structured Data in Commons claims in single API call\n",
    "# - support both Artwork (for 2D) and Art Photo (for 3D) templates in the Wikitext\n",
    "# - use appropriate SDC licenses for 3D works\n",
    "# - clean up code and convert login to an object\n",
    "# - remove hard-coded values and replace with YAML configuration file\n",
    "# - improve control of throttling between media file uploads to the Commons API\n",
    "# -----------------------------------------\n",
    "\n",
    "# Generic Commons API reference: https://commons.wikimedia.org/w/api.php\n",
    "\n",
    "# Description of bots on Commons: https://commons.wikimedia.org/wiki/Commons:Bots\n",
    "# See guidelines for operating a bot in Commons: https://commons.wikimedia.org/wiki/Commons:Bots/Requests\n",
    "# Need to decide whether this applies if non autonomous. It probably does.\n",
    "# Bot flag is an indication of community trust and prevents new images/recent changes lists from getting swamped.\n",
    "# It's also an indication of community trust; confirms edits not likely to need manual checking\n",
    "\n",
    "# ----------------\n",
    "# Module imports\n",
    "# ----------------\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "import requests\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "import sys\n",
    "import re # regex. Function to check for the particular form of xsd:dateTime required for full dates in Wikidata\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import webbrowser\n",
    "\n",
    "# AWS Python SDK\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Utility functions\n",
    "# ------------------------\n",
    "\n",
    "def read_dict(filename):\n",
    "    \"\"\"Read from a CSV file into a list of dictionaries.\"\"\"\n",
    "    with open(filename, 'r', newline='', encoding='utf-8') as file_object:\n",
    "        dict_object = csv.DictReader(file_object)\n",
    "        array = []\n",
    "        for row in dict_object:\n",
    "            array.append(row)\n",
    "    return array\n",
    "\n",
    "def write_dicts_to_csv(table, filename, fieldnames):\n",
    "    \"\"\"Write a list of dictionaries to a CSV file.\"\"\"\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csv_file_object:\n",
    "        writer = csv.DictWriter(csv_file_object, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "\n",
    "# ------------------------\n",
    "# Commons identifier/URL conversion functions\n",
    "# ------------------------\n",
    "\n",
    "# There are four identifiers used in Commons:\n",
    "\n",
    "# The most basic one is the filename, unencoded and with file extension.\n",
    "\n",
    "# The Commons web page URL is formed from the filename by prepending a subpath and \"File:\", replacing spaces in the filename with _, and URL-encoding the file name string\n",
    "# The reverse process may be lossy because it assumes that underscores should be turned into spaces and the filename might actuall contain underscores.\n",
    "\n",
    "# The Wikidata IRI identifier for the image is formed from the filename by URL-encoding it and prepending a subpath and \"Special:FilePath/\"\n",
    "# It the reverse process is lossless since it simply reverse URL-encodes the local name part of the IRI.\n",
    "\n",
    "# Each media page is also identified by an M ID, which is the Commons equivalent of a Q ID. Since structured\n",
    "# data on Commons is based on a Wikibase instance, the M ID is used when writing structured data to the API.\n",
    "\n",
    "def commons_url_to_filename(url):\n",
    "    \"\"\"Convert a Wikidata IRI identifier to an unencoded file name.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    The form of the URL is: http://commons.wikimedia.org/wiki/Special:FilePath/Castle%20De%20Haar%20%281892-1913%29%20-%20360%C2%B0%20Panorama%20of%20Castle%20%26%20Castle%20Grounds.jpg\n",
    "    \"\"\"\n",
    "    string = url.split(commons_prefix)[1] # get local name file part of URL\n",
    "    filename = urllib.parse.unquote(string) # reverse URL-encode the string\n",
    "    return filename\n",
    "\n",
    "def filename_to_commons_url(filename):\n",
    "    \"\"\"Convert a raw file name to a Wikidata IRI identifier.\"\"\"\n",
    "    encoded_filename = urllib.parse.quote(filename)\n",
    "    url = commons_prefix + encoded_filename\n",
    "    return url\n",
    "\n",
    "def commons_page_url_to_filename(url):\n",
    "    \"\"\"Convert a Commons web page URL to a raw file name.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    The form of the URL is: https://commons.wikimedia.org/wiki/File:Castle_De_Haar_(1892-1913)_-_360%C2%B0_Panorama_of_Castle_%26_Castle_Grounds.jpg\n",
    "    \"\"\"\n",
    "    string = url.split(commons_page_prefix)[1] # get local name file part of URL\n",
    "    string = string.replace('_', ' ')\n",
    "    filename = urllib.parse.unquote(string) # reverse URL-encode the string\n",
    "    return filename\n",
    "\n",
    "def filename_to_commons_page_url(filename):\n",
    "    \"\"\"Convert a raw file name to a Commons web page URL.\"\"\"\n",
    "    filename = filename.replace(' ', '_')\n",
    "    encoded_filename = urllib.parse.quote(filename)\n",
    "    url = commons_page_prefix + encoded_filename\n",
    "    url = url.replace('%28', '(').replace('%29', ')').replace('%2C', ',')\n",
    "    return url\n",
    "\n",
    "def get_commons_image_pageid(image_filename):\n",
    "    \"\"\"Look up the Commons image page ID (\"M ID\") using the image file name.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    The wbeditentity_upload function (which writes to a Wikibase API) needs the M ID, \n",
    "    the structured data on Commons equivalent of a Q ID. \n",
    "    \"\"\"\n",
    "    # get metadata for a photo including from file page\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'titles': 'File:' + image_filename,\n",
    "        'prop': 'info'\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://commons.wikimedia.org/w/api.php', params=params)\n",
    "    data = response.json()\n",
    "    #print(json.dumps(data, indent=2))\n",
    "    page_dict = data['query']['pages'] # this value is a dict that has the page IDs as keys\n",
    "    page_id_list = list(page_dict.keys()) # the result of the .keys() method is a \"dict_keys\" object, so coerce to a list\n",
    "    page_id = page_id_list[0] # info on only one page was requested, so get item 0\n",
    "    #print('Page ID:',page_id)\n",
    "    \n",
    "    # Don't think I need to add a sleep time for API reads, which are less resource-intensive\n",
    "    # than write operations. Also, only single requests are being made between operations that are time-consuming.\n",
    "    # NOTE: appears to return '-1' when it can't find the page.\n",
    "    return page_id\n",
    "    \n",
    "\n",
    "# ---------------------------\n",
    "# Body of main script\n",
    "# ---------------------------\n",
    "\n",
    "# This section contains configuration information and performs necessary logins\n",
    "# No writing is done, so it's \"safe\" to run any time\n",
    "\n",
    "# This section needs to be run prior to running any code that interacts with the Commons API\n",
    "# It generates the CSRF token required to post to the API on behalf of the user whose username and pwd are being used\n",
    "\n",
    "print('Loading data')\n",
    "\n",
    "# Load configuration values\n",
    "with open('commonsbot_config.yml', 'r') as file:\n",
    "    config_values = yaml.safe_load(file)\n",
    "\n",
    "if config_values['working_directory_path'] != '':\n",
    "    # Change working directory to image upload directory\n",
    "    os.chdir(config_values['working_directory_path'])\n",
    "    \n",
    "# These files are all relative to the current working directory\n",
    "\n",
    "# Note: setting the index to be the Q ID requires that qid has a unique value for each row. This should be the case.\n",
    "works_metadata = pd.read_csv('../works_multiprop.csv', na_filter=False, dtype = str)\n",
    "works_metadata.set_index('qid', inplace=True)\n",
    "\n",
    "raw_metadata = pd.read_csv('../gallery_works_renamed1.csv', na_filter=False, dtype = str)\n",
    "raw_metadata.set_index('accession_number', inplace=True)\n",
    "\n",
    "works_classification = pd.read_csv('../../gallery_buchanan/works_classification.csv', na_filter=False, dtype = str)\n",
    "works_classification.set_index('qid', inplace=True)\n",
    "\n",
    "works_ip_status = pd.read_csv('../items_status_abbrev.csv', na_filter=False, dtype = str)\n",
    "works_ip_status.set_index('qid', inplace=True)\n",
    "\n",
    "'''\n",
    "existing_images = pd.read_csv('commons_images.csv', na_filter=False, dtype = str) # Don't make the Q IDs the index!\n",
    "ip_status = works_ip_status.loc[index, 'status']\n",
    "if image_dimension_series['height'] * image_dimension_series['width'] < config_values['minimum_pixel_squared']:\n",
    "    print('Image too small.')\n",
    "image_metadata['creator_string'] = raw_metadata.loc[image_metadata['inventory_number']]['creator_string']\n",
    "'''\n",
    "\n",
    "inventory_numbers = works_metadata['inventory_number'].tolist()\n",
    "print(inventory_numbers)\n",
    "\n",
    "image_dimensions = pd.read_csv('image_dimensions.csv', na_filter=False, dtype = str)\n",
    "# Convert some columns to integers\n",
    "image_dimensions[['kilobytes', 'height', 'width']] = image_dimensions[['kilobytes', 'height', 'width']].astype(int)\n",
    "\n",
    "#image = image_dimensions.head(500)\n",
    "images = image_dimensions\n",
    "\n",
    "regex = '^[0-9]+$'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, image in images.iterrows():\n",
    "    acc_index_pieces = image['accession'].split('.')[1:]\n",
    "    acc_index = '.'.join(acc_index_pieces)\n",
    "    #print(acc_index)\n",
    "    numeric = bool(re.search(regex, acc_index))\n",
    "    if not numeric:\n",
    "        if acc_index[-1] != 'P':\n",
    "            constructed_inven = str(image['subdir']) + '.' + acc_index\n",
    "            if not constructed_inven in inventory_numbers:\n",
    "                print(constructed_inven)\n",
    "    #print()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
