# Notes for phase 2

The first task was to create items for artwork items when incorrectly linked to non-artwork items. This was basically a test run of about 100 Commons works.

## Purpose and sources of files in this directory

**compare_metadata_sources.ipynb** in the `processed_lists` folder is the script that generated source files used in this directory. 

**works_already_in_wikidata.csv** Used as a data source by [compare_metadata_sources.ipynb](), it contains the running mappings between ACT IDs and Q IDs of items in Wikidata that have been linked to ACT. In the first part of phase 2, this was used to limit the new creation of artworks to Commons items that were linked to the wrong kind of item (and that needed to have an artwork item created for them). In the second part of phase 2, we will use this to exclude works that are already in Wikidata, and create new items for Commons works used as a source for ACT. 

**act_all_202109241353_repaired.csv** Used as a data source by [compare_metadata_sources.ipynb](), it contains the repaired metadata dump from ACT. Quality is high.

**already_in_templated_data.csv** Used as a data source by [compare_metadata_sources.ipynb](), it contains data about Commons works scraped from the templated part of their web pages. The `artwork` template has a lot of data, the `information` template had minimal data.

**clean_ids.csv** used as input for [create_act_items.ipynb]() to match rows in different tables using different unique identifiers.

**collections.csv** manually created file for matching museum and gallery names found in the Commons download with their Q IDs. I'm not sure that I actually used it.

**country_mappings.csv** Used to get country Q IDs based on names. This was created earlier as part of the Gallery project.

**screens.json** This contains SPARQL graph patterns used by the artist disambiguation function to ignore categories of people like "Ming dynasty person". Developed for the Gallery project.

**create_act_items.ipynb** This is the [primary script](https://github.com/HeardLibrary/vandycite/blob/master/act/create_items/create_act_items.ipynb) used to create Wikidata items for ACT artwork. Its main source files were [act_data_fix.csv]() and [commons_data_fix.csv](), but it also used [clean_ids.csv]() to join tables by shared identifiers. The output was **abstract_artworks_out.csv**, which when cleaned up became [abstract_artworks.csv](), used by VanderBot to do the upload. 

**act_data_fix.csv** This is the primary source of metadata for Commons items extracted from the cleaned-up ACT database dump, [act_all_202109241353_repaired.csv]() to be used in the first task. It was generated by the [compare_metadata_sources.ipynb]() script.

**commons_data_fix.csv** Created by the [compare_metadata_sources.ipynb]() script, data retrieved from Commons in the [already_in_templated_data.csv]() was screened by a SPARQL query, then indexed to Wikidata items already in and the ACT ID. This was used as a complementary data source to the [act_data_fix.csv]() when creating the output CSV for VanderBot to use to do the upload.

**abstract_artworks.csv** is the output of the [create_act_items.ipynb]() used for the VanderBot upload.

**unidentified_artists.json** output of [create_act_items.ipynb]() used to disambiguate possible artist matches during cleanup.

**language_labels.json** [create_act_items.ipynb]() that might be usable in the future to create multilingual labels for works.


-----

Last updated 2022-01-26
