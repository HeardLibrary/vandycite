{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is based on instructions given in [this lesson](https://github.com/HeardLibrary/digital-scholarship/blob/master/code/scrape/pylesson/lesson2-api.ipynb). \n",
    "\n",
    "## Import libraries and load API key from file\n",
    "\n",
    "The API key should be the only item in a text file called `flickr_api_key.txt` located in the user's home directory. No trailing newline and don't include the \"secret\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from time import sleep\n",
    "import webbrowser\n",
    "import pandas as pd\n",
    "\n",
    "api_sleep = 1 # Flickr API limits calls to 1/second, so throttle by inserting a delay of 1 s after each call\n",
    "\n",
    "# define some canned functions we need to use\n",
    "\n",
    "# write a list of dictionaries to a CSV file\n",
    "def write_dicts_to_csv(table, filename, fieldnames):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csv_file_object:\n",
    "        writer = csv.DictWriter(csv_file_object, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "\n",
    "def get_license_history(photo_id):\n",
    "    endpoint_url = 'https://www.flickr.com/services/rest'\n",
    "    method = 'flickr.photos.licenses.getLicenseHistory'\n",
    "\n",
    "    param_dict = {\n",
    "        'method' : method,\n",
    "        #'per_page' : '1',  # default is 100, maximum is 500. Use paging to retrieve more than 500.\n",
    "        #'page' : '1',\n",
    "        'photo_id' : photo_id,\n",
    "        'api_key' : api_key,\n",
    "        'nojsoncallback' : '1', # this parameter causes the API to return actual JSON instead of its weird default string\n",
    "        'format' : 'json' # overrides the default XML serialization for the search results\n",
    "        }\n",
    "\n",
    "    #print(param_dict)\n",
    "    metadata_response = requests.get(endpoint_url, params = param_dict)\n",
    "\n",
    "    # print(metadata_response.url) # uncomment this if testing is needed, again don't reveal key in notebook\n",
    "    data = metadata_response.json()\n",
    "\n",
    "    #print(json.dumps(data, indent=4))\n",
    "    if data['stat'] == 'ok':\n",
    "        sleep(api_sleep)\n",
    "        license_history = data['license_history']\n",
    "        return license_history\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "home = str(Path.home()) #gets path to home directory; supposed to work for Win and Mac\n",
    "key_filename = 'flickr-api-keys-tang-song.txt'\n",
    "api_key_path = home + '/' + key_filename\n",
    "\n",
    "try:\n",
    "    with open(api_key_path, 'rt', encoding='utf-8') as file_object:\n",
    "        api_key = file_object.read()\n",
    "        if api_key[-1] == '\\n':\n",
    "            print('Warning: your key has a trailing newline that needs to be deleted!')\n",
    "        # print(api_key) # delete this line once the script is working; don't want the key as part of the notebook\n",
    "except:\n",
    "    print(key_filename + ' file not found - is it in your home directory?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_metadata = pd.read_csv('act_all_202209291736.csv', na_filter=False, dtype = str)\n",
    "image_metadata = image_metadata.set_index('RecordNumber')\n",
    "image_url_df = image_metadata.loc[:, 'CopyrightStatement':'CopyrightStatement'].copy()\n",
    "image_url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_url_df = image_url_df.loc[image_url_df['CopyrightStatement'].str.contains('flickr.com', case=False)]\n",
    "flickr_url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for act_id, image in flickr_url_df.iterrows():\n",
    "    url = image['CopyrightStatement']\n",
    "    out_dict = {'act_id': act_id, 'url': url}\n",
    "    print(act_id, url)\n",
    "    \n",
    "    # Handle edge case where \"http\" is omitted \n",
    "    if 'http' in url:\n",
    "        photo_id = image['CopyrightStatement'].split('/')[5]\n",
    "    else:\n",
    "        photo_id = image['CopyrightStatement'].split('/')[3]\n",
    "        \n",
    "    # In cases where there is text following the URL, remove it.\n",
    "    if ' ' in photo_id:\n",
    "        photo_id = photo_id.split(' ')[0]\n",
    "    print(photo_id)\n",
    "\n",
    "    fail = False\n",
    "    \n",
    "    # Handle edge case where there isn't any image number in the URL\n",
    "    if photo_id == '':\n",
    "        out_dict['license'] = ''\n",
    "        out_dict['flickr_id'] = ''\n",
    "        fail = True\n",
    "    else:\n",
    "        out_dict['flickr_id'] = photo_id\n",
    "        licenses = get_license_history(photo_id)\n",
    "        #print(licenses)\n",
    "\n",
    "        if licenses is None:\n",
    "            out_dict['license'] = ''\n",
    "            fail = True\n",
    "        elif len(licenses) == 0:\n",
    "            out_dict['license'] = ''\n",
    "            fail = True\n",
    "        elif len(licenses) > 1:\n",
    "            out_dict['license'] = licenses\n",
    "            fail = True\n",
    "        else:\n",
    "            if licenses[0]['old_license'] == 'All Rights Reserved':\n",
    "                out_dict['license'] = 'All Rights Reserved'\n",
    "            elif 'publicdomain' in licenses[0]['old_license_url']:\n",
    "                out_dict['license'] = 'zero/1.0/'                \n",
    "            else:\n",
    "                out_dict['license'] = licenses[0]['old_license_url'].split('https://creativecommons.org/licenses/')[1]\n",
    "                \n",
    "            if licenses[0]['new_license'] == 'All Rights Reserved':\n",
    "                out_dict['new_license'] = 'All Rights Reserved'\n",
    "            else:\n",
    "                if licenses[0]['new_license_url'] == '':\n",
    "                    out_dict['new_license'] = ''\n",
    "                elif 'publicdomain' in licenses[0]['new_license_url']:\n",
    "                    out_dict['new_license'] = 'zero/1.0/'                \n",
    "                else:\n",
    "                    out_dict['new_license'] = licenses[0]['new_license_url'].split('https://creativecommons.org/licenses/')[1]\n",
    "    if fail:\n",
    "        out_dict['new_license'] = ''\n",
    "    \n",
    "    results.append(out_dict)\n",
    "    \n",
    "    # write the data to a file after each image in case script crashes\n",
    "    filename = 'licenses.csv'\n",
    "    fieldnames = out_dict.keys() # use the keys from the last dictionary for column headers; assume all are the same\n",
    "    write_dicts_to_csv(results, filename, fieldnames)\n",
    "\n",
    "    print()\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the loops to do the paging\n",
    "\n",
    "Flickr limits the number of photos that can be requested to 500. Since we have more than that, we need to request the data 500 photos at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_page = 5   # use 500 for full download, use smaller number like 5 for testing\n",
    "pages = number_photos // per_page   # the // operator returns the integer part of the division (\"floor\")\n",
    "table = []\n",
    "\n",
    "#for page_number in range(0, pages + 1):  # need to add one to get the final partial page\n",
    "for page_number in range(0, 1):  # use this to do only one page for testing\n",
    "    print('retrieving page ', page_number + 1)\n",
    "    page_string = str(page_number + 1)\n",
    "    param_dict = {\n",
    "        'method' : method,\n",
    "        'extras' : 'description,license,original_format,date_taken,original_format,geo,tags,machine_tags,media,url_t,url_o',\n",
    "        'per_page' : str(per_page),  # default is 100, maximum is 500.\n",
    "        'page' : page_string,\n",
    "        'user_id' : user_id,\n",
    "        'oauth_consumer_key' : api_key,\n",
    "        'nojsoncallback' : '1', # this parameter causes the API to return actual JSON instead of its weird default string\n",
    "        'format' : 'json' # overrides the default XML serialization for the search results\n",
    "        }\n",
    "    metadata_response = requests.get(endpoint_url, params = param_dict)\n",
    "    data = metadata_response.json()\n",
    "#    print(json.dumps(data, indent=4))  # uncomment this line for testing\n",
    "    \n",
    "    # data['photos']['photo'] is the number of photos for which data was returned\n",
    "    for image_number in range(0, len(data['photos']['photo'])):\n",
    "        photo_dictionary = extract_data(image_number, data)\n",
    "        table.append(photo_dictionary)\n",
    "\n",
    "    # write the data to a file\n",
    "    # We could just do this for all the data at the end.\n",
    "    # But if the search fails in the middle, we will at least get partial results\n",
    "    fieldnames = photo_dictionary.keys() # use the keys from the last dictionary for column headers; assume all are the same\n",
    "    write_dicts_to_csv(table, filename, fieldnames)\n",
    "\n",
    "    sleep(1) # wait a second to avoid getting blocked for hitting the API to rapidly\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
