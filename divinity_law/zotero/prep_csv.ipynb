{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'constants': [],\n",
       " 'properties': [{'variable': 'full_work_available',\n",
       "   'value': 'identity',\n",
       "   'source': 'full_work_available',\n",
       "   'ref': [{'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'edition_version',\n",
       "   'value': 'identity',\n",
       "   'source': 'edition_version'},\n",
       "  {'variable': 'language', 'value': 'detect_language', 'source': 'label'},\n",
       "  {'variable': 'number_pages', 'value': 'calculate_pages', 'source': 'page'},\n",
       "  {'variable': 'doi',\n",
       "   'value': 'clean_doi',\n",
       "   'source': 'doi',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'pmid',\n",
       "   'value': 'identity',\n",
       "   'source': 'pmid',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'publication_date',\n",
       "   'value': 'identity',\n",
       "   'source': 'publication_date',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'title_en',\n",
       "   'value': 'identity',\n",
       "   'source': 'label',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'published_in',\n",
       "   'value': 'disambiguate_published_in',\n",
       "   'source': 'published_in',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'volume',\n",
       "   'value': 'identity',\n",
       "   'source': 'volume',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'page',\n",
       "   'value': 'identity',\n",
       "   'source': 'page',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'issue',\n",
       "   'value': 'identity',\n",
       "   'source': 'issue',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'isbn10',\n",
       "   'value': 'identity',\n",
       "   'source': 'isbn10',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'isbn13',\n",
       "   'value': 'identity',\n",
       "   'source': 'isbn13',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'publisher',\n",
       "   'value': 'disambiguate_publisher',\n",
       "   'source': 'publisher',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]},\n",
       "  {'variable': 'place_of_publication',\n",
       "   'value': 'disambiguate_place_of_publication',\n",
       "   'source': 'place_of_publication',\n",
       "   'ref': [{'variable': 'referenceUrl', 'value': 'reference'},\n",
       "    {'variable': 'retrieved', 'value': 'today'}]}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz # fuzzy logic matching\n",
    "from langdetect import detect_langs\n",
    "\n",
    "default_language = 'en'\n",
    "precision_cutoff = 0.95\n",
    "phrase_length_cutoff = 2\n",
    "\n",
    "# !!! Need to set up an error log!\n",
    "\n",
    "with open('config.yaml', 'r') as file_object:\n",
    "    config = yaml.safe_load(file_object)\n",
    "\n",
    "with open('mapping.yaml', 'r') as file_object:\n",
    "    mapping = yaml.safe_load(file_object)\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_local_name(iri):\n",
    "    \"\"\"Extract the local name part of an IRI, e.g. a Q ID from a Wikidata IRI\"\"\"\n",
    "    # pattern is http://www.wikidata.org/entity/Q6386232\n",
    "    pieces = iri.split('/')\n",
    "    return pieces[-1]\n",
    "\n",
    "def extract_metadata(config, work_data):\n",
    "    out_dict = {'qid': ''}\n",
    "    \n",
    "    for property in config['outfiles'][0]['prop_list']:\n",
    "        field = property['variable']\n",
    "        out_dict[field + '_uuid'] = ''\n",
    "        \n",
    "        if field in work_data:\n",
    "            if work_data[field] == '':\n",
    "                output_value = ''\n",
    "                no_value = True\n",
    "            else:\n",
    "                output_value = work_data[field]\n",
    "                no_value = False\n",
    "        else:\n",
    "            output_value = ''\n",
    "            no_value = True\n",
    "\n",
    "        # Populate the values-related columns\n",
    "        if property['value_type'] == 'date':\n",
    "            out_dict[field + '_nodeId'] = ''\n",
    "            out_dict[field + '_val'] = output_value\n",
    "            out_dict[field + '_prec'] = ''\n",
    "            \n",
    "        elif property['value_type'] == 'quantity':\n",
    "            out_dict[field + '_nodeId'] = ''\n",
    "            out_dict[field + '_val'] = output_value\n",
    "            if no_value:\n",
    "                out_dict[field + '_unit'] = ''\n",
    "            else:\n",
    "                out_dict[field + '_unit'] = work_data[field + '_unit']\n",
    "            \n",
    "        elif property['value_type'] == 'globecoordinate':\n",
    "            out_dict[field + '_nodeId'] = ''\n",
    "            out_dict[field + '_val'] = output_value\n",
    "            if no_value:\n",
    "                out_dict[field + '_long'] = ''\n",
    "                out_dict[field + '_prec'] = ''\n",
    "            else:\n",
    "                out_dict[field + '_long'] = work_data[field + '_long']\n",
    "                out_dict[field + '_prec'] = work_data[field + '_prec']\n",
    "\n",
    "        else:\n",
    "            out_dict[field] = output_value\n",
    "            \n",
    "        # Populate the qualifier columns\n",
    "        for qualifier in property['qual']:\n",
    "            qual_field = field + '_' + qualifier['variable']\n",
    "            # To my knowledge, dates are the only complex types used as qualifiers (no quantities or globecoordinates).\n",
    "            if qualifier['value_type'] == 'date':\n",
    "                out_dict[qual_field + '_nodeId'] = ''\n",
    "                if no_value:\n",
    "                    out_dict[qual_field + '_val'] = ''\n",
    "                else:\n",
    "                    out_dict[qual_field + '_val'] = work_data[qual_field]\n",
    "                out_dict[qual_field + '_prec'] = ''\n",
    "            else:\n",
    "                if no_value:\n",
    "                    out_dict[qual_field] = ''\n",
    "                else:\n",
    "                    out_dict[qual_field] = work_data[qual_field]\n",
    "                \n",
    "        # Populate the reference columns\n",
    "        # There's only a hash ID column if there's at least one reference.\n",
    "        if len(property['ref']) > 0:\n",
    "            out_dict[field + '_ref1_hash'] = ''\n",
    "        for reference in property['ref']:\n",
    "            ref_field = field + '_ref1_' + reference['variable']\n",
    "            # To my knowledge, dates are the only complex types used as qualifiers (no quantities or globecoordinates).\n",
    "            if reference['value_type'] == 'date':\n",
    "                out_dict[ref_field + '_nodeId'] = ''\n",
    "                if no_value:\n",
    "                    out_dict[ref_field + '_val'] = ''\n",
    "                else:\n",
    "                    out_dict[ref_field + '_val'] = work_data[field + '_' + reference['variable']]\n",
    "                out_dict[ref_field + '_prec'] = ''\n",
    "            else:\n",
    "                if no_value:\n",
    "                    out_dict[ref_field] = ''\n",
    "                else:\n",
    "                    out_dict[ref_field] = work_data[field + '_' + reference['variable']]\n",
    "        \n",
    "    return out_dict\n",
    "\n",
    "\n",
    "work_data = {'qid': '',\n",
    " #'label': 'Book Review: Theologie aus asiatischen Quellen: Der theologische Weg Choan-Seng Songs vor dem Hintergrund der asiatischen ökumenischen Diskussion',\n",
    " #'label': 'Chinese Accounts of the Strange: A Study in the History of Religions',\n",
    " 'label': 'Le péché contre le sang : la syphilis et la construction de l’identité juive',\n",
    " #'label': 'Shenxian zhuan 神仙傳',\n",
    " 'full_work_available': 'https://purl.stanford.edu/gc695hq2680',\n",
    " 'full_work_available_retrieved': '2022-02-18',\n",
    " 'edition_version': '',\n",
    " 'language': 'Q1860',\n",
    " 'number_pages': '18',\n",
    " 'number_pages_unit': 'Q1069725',\n",
    " 'doi': '10.1093/oxfordhb/9780190221171.013.34',\n",
    " 'doi_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'doi_retrieved': '2022-08-21',\n",
    " 'pmid': '29097536',\n",
    " 'pmid_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'pmid_retrieved': '2022-08-21',\n",
    " 'publication_date': '2013-07-14',\n",
    " 'publication_date_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'publication_date_retrieved': '2022-08-21',\n",
    " 'title_en': 'Orthography, Textual Criticism, and the Poetry of Job',\n",
    " 'title_en_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'title_en_retrieved': '2022-08-21',\n",
    " 'published_in': 'Q4041879',\n",
    " 'published_in_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'published_in_retrieved': '2022-08-21',\n",
    " 'volume': '101',\n",
    " 'volume_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'volume_retrieved': '2022-08-21',\n",
    " 'page': '1464-1465',\n",
    " 'page_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'page_retrieved': '2022-08-21',\n",
    " 'issue': '4',\n",
    " 'issue_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'issue_retrieved': '2022-08-21',\n",
    " 'isbn10': '0-8070-8592-8',\n",
    " 'isbn10_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'isbn10_retrieved': '2022-08-21',\n",
    " 'isbn13': '978-1-5416-4497-7',\n",
    " 'isbn13_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'isbn13_retrieved': '2022-08-21',\n",
    " 'publisher': 'Stanford University Press',\n",
    " 'publisher_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'publisher_retrieved': '2022-08-21',\n",
    " 'place_of_publication': 'Q173813',\n",
    " 'place_of_publication_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
    " 'place_of_publication_retrieved': '2022-08-21'}\n",
    "\"\"\"\n",
    "work_data = work_data = {'qid': '',\n",
    " 'author': 'Q86508256',\n",
    " 'author_series_ordinal': '1',\n",
    " 'author_stated_as': 'Fernando F. Segovia'}\n",
    "\"\"\"\n",
    "\n",
    "def identity(value):\n",
    "    \"\"\"Return the value argument with any leading and trailing whitespace removed.\"\"\"\n",
    "    return value.strip()\n",
    "\n",
    "def detect_language(string):\n",
    "    \"\"\"Detect the language of the label.\"\"\"\n",
    "    try:\n",
    "        lang_list = detect_langs(string)\n",
    "        lang_string = str(lang_list[0])\n",
    "        confidence = float(lang_string[3:])\n",
    "        lang = lang_string[:2]\n",
    "    except: #exceptions occur when no info to decide, e.g. numbers\n",
    "        lang = 'zxx'\n",
    "        confidence = float(0)\n",
    "    if confidence < precision_cutoff:\n",
    "        print('Warning: language confidence below', precision_cutoff, ':', confidence)\n",
    "    return lang\n",
    "\n",
    "def integer_value(r):\n",
    "    \"\"\"Return value of Roman numeral symbol.\n",
    "    \n",
    "    Note:\n",
    "    -----\n",
    "    Code from https://www.geeksforgeeks.org/python-program-for-converting-roman-numerals-to-decimal-lying-between-1-to-3999/\"\"\"    \n",
    "    if (r == 'I'):\n",
    "        return 1\n",
    "    if (r == 'V'):\n",
    "        return 5\n",
    "    if (r == 'X'):\n",
    "        return 10\n",
    "    if (r == 'L'):\n",
    "        return 50\n",
    "    if (r == 'C'):\n",
    "        return 100\n",
    "    if (r == 'D'):\n",
    "        return 500\n",
    "    if (r == 'M'):\n",
    "        return 1000\n",
    "    return -1\n",
    "\n",
    "def roman_to_decimal(numeral):\n",
    "    \"\"\"Convert Roman numerals to integers.\n",
    "    \n",
    "    Note:\n",
    "    -----\n",
    "    Code from https://www.geeksforgeeks.org/python-program-for-converting-roman-numerals-to-decimal-lying-between-1-to-3999/\"\"\"\n",
    "    str = numeral.upper()\n",
    "    res = 0\n",
    "    i = 0\n",
    "\n",
    "    while (i < len(str)):\n",
    "\n",
    "        # Getting value of symbol s[i]\n",
    "        s1 = integer_value(str[i])\n",
    "        \n",
    "        # Return a negative number if error.\n",
    "        if s1 < 0:\n",
    "            return -1\n",
    "\n",
    "        if (i + 1 < len(str)):\n",
    "\n",
    "            # Getting value of symbol s[i + 1]\n",
    "            s2 = integer_value(str[i + 1])\n",
    "            \n",
    "            # Return a negative number if error.\n",
    "            if s2 < 0:\n",
    "                return -1\n",
    "\n",
    "            # Comparing both values\n",
    "            if (s1 >= s2):\n",
    "\n",
    "                # Value of current symbol is greater\n",
    "                # or equal to the next symbol\n",
    "                res = res + s1\n",
    "                i = i + 1\n",
    "            else:\n",
    "\n",
    "                # Value of current symbol is greater\n",
    "                # or equal to the next symbol\n",
    "                res = res + s2 - s1\n",
    "                i = i + 2\n",
    "        else:\n",
    "            res = res + s1\n",
    "            i = i + 1\n",
    "\n",
    "    return res\n",
    "\n",
    "def calculate_pages(range):\n",
    "    \"\"\"Calculate the number of pages from the page range.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    Supports properly formatted Roman numerals and doesn't care about whitespace.\"\"\"\n",
    "    numbers = range.split('-')\n",
    "    \n",
    "    # If there is only a single number or an empty cell, return the empty string.\n",
    "    if len(numbers) < 2:\n",
    "        return ''\n",
    "    # Edge case where it isn't a well-formed range and has multiple hyphens\n",
    "    if len(numbers) > 2:\n",
    "        return ''\n",
    "    \n",
    "    # Step through the two numbers to try to convert them from Roman numerals if not integers.\n",
    "    for index, number in enumerate(numbers):\n",
    "        number = number.strip()\n",
    "        if not number.isnumeric():\n",
    "            numbers[index] = roman_to_decimal(number)\n",
    "            \n",
    "            # Will return -1 error if it contains characters not valid for Roman numerals \n",
    "            if numbers[index] < 0:\n",
    "                return ''\n",
    "    \n",
    "    number_pages = int(numbers[1]) - int(numbers[0]) + 1 # Need to add one since first page in range counts\n",
    "    if number_pages < 1:\n",
    "        return ''\n",
    "    return str(number_pages)\n",
    "    \n",
    "    return value\n",
    "\n",
    "def clean_doi(value):\n",
    "    \"\"\"Turn DOI into uppercase and remove leading and trailing whitespace.\"\"\"\n",
    "    cleaned_value = value.upper().strip()\n",
    "    return cleaned_value\n",
    "\n",
    "def disambiguate_published_in(value):\n",
    "    \"\"\"Use the value in the ISSN column to try to find the containing work.\n",
    "    \n",
    "    Note:\n",
    "    -----\n",
    "    For journal articles, this performs a legitimate WQS search for the journal title using the ISSN.\n",
    "    For book chapters, the ISSN column may contain the Q ID of the containing book, inserted there during\n",
    "    a pre-processing step (a hack, but typically books would not have an ISSN and this column would be empty).\"\"\"\n",
    "    if value == '':\n",
    "        return value\n",
    "    \n",
    "    # The value is a Q ID and was determined during a pre-processing step (i.e. for book chapters)\n",
    "    if value[0] == 'Q':\n",
    "        return value\n",
    "\n",
    "    # Look up the ISSN from CrossRef in Wikidata\n",
    "    # Build query string\n",
    "    query_string = '''select distinct ?container ?containerLabel where {\n",
    "      ?container wdt:P236 ''' + value + '''.\n",
    "      optional {\n",
    "      ?container rdfs:label ?containerLabel.\n",
    "      filter(lang(?containerLabel)=\"''' + default_language + '''\")\n",
    "      }\n",
    "    }'''\n",
    "    #print(query_string)\n",
    "\n",
    "    # Send query to endpoint\n",
    "    query_results = send_sparql_query(query_string)\n",
    "    #pp.pprint(query_results)\n",
    "\n",
    "    # !!!!!!!!!!!!!!!!!! Enable this code when the error log is set up\n",
    "    \"\"\"\n",
    "    if len(query_results) > 1:\n",
    "        print('Warning! More than one container in Wikidata matched the ISSN ', file=log_object)\n",
    "        print(query_results, '\\n', file=log_object)\n",
    "    \"\"\"\n",
    "    # Extract Q ID from SPARQL query results. If there is more than one result, the last one will be used for the Q ID\n",
    "    for result in query_results:\n",
    "        container_qid = extract_local_name(result['container']['value'])\n",
    "        # Skipping this since container name isn't passed into the function.\n",
    "        \"\"\"\n",
    "        journal_name = result['containerLabel']['value']\n",
    "        if journal_name != crossref_results['journal_title']:\n",
    "            # NOTE: did empirical testing to see which kind of fuzzy matching worked best\n",
    "            #ratio = fuzz.ratio(journal_name, crossref_results['journal_title'])\n",
    "            #partial_ratio = fuzz.partial_ratio(journal_name, crossref_results['journal_title'])\n",
    "            #sort_ratio = fuzz.token_sort_ratio(journal_name, crossref_results['journal_title'])\n",
    "            #set_ratio = fuzz.token_set_ratio(journal_name, crossref_results['journal_title'])\n",
    "            w_ratio = fuzz.WRatio(journal_name, crossref_results['journal_title'])\n",
    "            #print('name similarity ratio', ratio)\n",
    "            #print('partial ratio', partial_ratio)\n",
    "            #print('sort_ratio', sort_ratio)\n",
    "            #print('set_ratio', set_ratio)\n",
    "            if w_ratio < 99:\n",
    "                print('article:', crossref_results['label_' + default_language], 'w_ratio:', w_ratio, 'Warning: Wikidata journal: \"' + journal_name + '\"', journal_qid, 'does not match CrossRef journal title: \"' + crossref_results['journal_title'] + '\"\\n', file=log_object)\n",
    "        #print('article:', crossref_results['label_' + default_language], 'journal:', journal_qid, journal_name)\n",
    "        \"\"\"\n",
    "    return container_qid\n",
    "\n",
    "\n",
    "def disambiguate_publisher(name_string):\n",
    "    \"\"\"Look up the publisher Q ID from a list derived from a SPARQL query https://w.wiki/4pbi\"\"\"\n",
    "    # Set publisher Q ID to empty string if there's no publisher string\n",
    "    if name_string == '':\n",
    "        return ''\n",
    "    \n",
    "    best_match_score = 0\n",
    "    best_match = ''\n",
    "    best_match_label = ''\n",
    "    for qid, publisher in publishers.iterrows():  # The publishers DataFrame is a global variable\n",
    "        w_ratio = fuzz.WRatio(name_string, publisher['label'])\n",
    "        if w_ratio > best_match_score:\n",
    "            best_match = qid\n",
    "            best_match_label = publisher['label']\n",
    "            best_match_score = w_ratio\n",
    "            \n",
    "    if best_match_score < 98:\n",
    "        print('w_ratio:', best_match_score, 'Warning: poor match of: \"' + best_match_label + '\"', best_match, 'to CrossRef publisher: \"' + name_string + '\"\\n')\n",
    "        #print('w_ratio:', best_match_score, 'Warning: poor match of: \"' + best_match_label + '\"', best_match, 'to CrossRef publisher: \"' + name_string + '\"\\n', file=log_object)\n",
    "    return best_match\n",
    "\n",
    "def disambiguate_place_of_publication(value):\n",
    "    \"\"\"Return the value argument unchanged.\"\"\"\n",
    "    return value\n",
    "\n",
    "def today():\n",
    "    \"\"\"Generate the current UTC xsd:date\"\"\"\n",
    "    whole_time_string_z = datetime.datetime.utcnow().isoformat() # form: 2019-12-05T15:35:04.959311\n",
    "    date_z = whole_time_string_z.split('T')[0] # form 2019-12-05\n",
    "    return date_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q6386232'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iri = 'http://www.wikidata.org/entity/Q6386232'\n",
    "extract_local_name(iri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_work_available identity\n",
      "https://purl.stanford.edu/gc695hq2680\n",
      "\n",
      "edition_version identity\n",
      "\n",
      "\n",
      "language detect_language\n",
      "fr\n",
      "\n",
      "number_pages calculate_pages\n",
      "2\n",
      "\n",
      "doi clean_doi\n",
      "10.1093/OXFORDHB/9780190221171.013.34\n",
      "\n",
      "pmid identity\n",
      "29097536\n",
      "\n",
      "publication_date identity\n",
      "2013-07-14\n",
      "\n",
      "title_en identity\n",
      "Le péché contre le sang : la syphilis et la construction de l’identité juive\n",
      "\n",
      "published_in disambiguate_published_in\n",
      "Q4041879\n",
      "\n",
      "volume identity\n",
      "101\n",
      "\n",
      "page identity\n",
      "1464-1465\n",
      "\n",
      "issue identity\n",
      "4\n",
      "\n",
      "isbn10 identity\n",
      "0-8070-8592-8\n",
      "\n",
      "isbn13 identity\n",
      "978-1-5416-4497-7\n",
      "\n",
      "publisher disambiguate_publisher\n",
      "Q1479937\n",
      "\n",
      "place_of_publication disambiguate_place_of_publication\n",
      "Q173813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "publishers = pd.read_csv('publishers.csv', na_filter=False, dtype = str)\n",
    "publishers.set_index('qid', inplace=True)\n",
    "\n",
    "for prop in mapping['properties']:\n",
    "    print(prop['variable'], prop['value'])\n",
    "    expression = prop['value'] + \"('\" + work_data[prop['source']] + \"')\"\n",
    "    output = eval(expression)\n",
    "    print(output)\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': '',\n",
       " 'full_work_available_uuid': '',\n",
       " 'full_work_available': 'https://purl.stanford.edu/gc695hq2680',\n",
       " 'full_work_available_ref1_hash': '',\n",
       " 'full_work_available_ref1_retrieved_nodeId': '',\n",
       " 'full_work_available_ref1_retrieved_val': '2022-02-18',\n",
       " 'full_work_available_ref1_retrieved_prec': '',\n",
       " 'edition_version_uuid': '',\n",
       " 'edition_version': '',\n",
       " 'language_uuid': '',\n",
       " 'language': 'Q1860',\n",
       " 'number_pages_uuid': '',\n",
       " 'number_pages_nodeId': '',\n",
       " 'number_pages_val': '18',\n",
       " 'number_pages_unit': 'Q1069725',\n",
       " 'doi_uuid': '',\n",
       " 'doi': '10.1093/OXFORDHB/9780190221171.013.34',\n",
       " 'doi_ref1_hash': '',\n",
       " 'doi_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'doi_ref1_retrieved_nodeId': '',\n",
       " 'doi_ref1_retrieved_val': '2022-08-21',\n",
       " 'doi_ref1_retrieved_prec': '',\n",
       " 'pmid_uuid': '',\n",
       " 'pmid': '29097536',\n",
       " 'pmid_ref1_hash': '',\n",
       " 'pmid_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'pmid_ref1_retrieved_nodeId': '',\n",
       " 'pmid_ref1_retrieved_val': '2022-08-21',\n",
       " 'pmid_ref1_retrieved_prec': '',\n",
       " 'publication_date_uuid': '',\n",
       " 'publication_date_nodeId': '',\n",
       " 'publication_date_val': '2013-07-14',\n",
       " 'publication_date_prec': '',\n",
       " 'publication_date_ref1_hash': '',\n",
       " 'publication_date_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'publication_date_ref1_retrieved_nodeId': '',\n",
       " 'publication_date_ref1_retrieved_val': '2022-08-21',\n",
       " 'publication_date_ref1_retrieved_prec': '',\n",
       " 'title_en_uuid': '',\n",
       " 'title_en': 'Orthography, Textual Criticism, and the Poetry of Job',\n",
       " 'title_en_ref1_hash': '',\n",
       " 'title_en_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'title_en_ref1_retrieved_nodeId': '',\n",
       " 'title_en_ref1_retrieved_val': '2022-08-21',\n",
       " 'title_en_ref1_retrieved_prec': '',\n",
       " 'published_in_uuid': '',\n",
       " 'published_in': 'Q4041879',\n",
       " 'published_in_ref1_hash': '',\n",
       " 'published_in_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'published_in_ref1_retrieved_nodeId': '',\n",
       " 'published_in_ref1_retrieved_val': '2022-08-21',\n",
       " 'published_in_ref1_retrieved_prec': '',\n",
       " 'volume_uuid': '',\n",
       " 'volume': '101',\n",
       " 'volume_ref1_hash': '',\n",
       " 'volume_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'volume_ref1_retrieved_nodeId': '',\n",
       " 'volume_ref1_retrieved_val': '2022-08-21',\n",
       " 'volume_ref1_retrieved_prec': '',\n",
       " 'page_uuid': '',\n",
       " 'page': '1464-1465',\n",
       " 'page_ref1_hash': '',\n",
       " 'page_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'page_ref1_retrieved_nodeId': '',\n",
       " 'page_ref1_retrieved_val': '2022-08-21',\n",
       " 'page_ref1_retrieved_prec': '',\n",
       " 'issue_uuid': '',\n",
       " 'issue': '4',\n",
       " 'issue_ref1_hash': '',\n",
       " 'issue_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'issue_ref1_retrieved_nodeId': '',\n",
       " 'issue_ref1_retrieved_val': '2022-08-21',\n",
       " 'issue_ref1_retrieved_prec': '',\n",
       " 'isbn10_uuid': '',\n",
       " 'isbn10': '0-8070-8592-8',\n",
       " 'isbn10_ref1_hash': '',\n",
       " 'isbn10_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'isbn10_ref1_retrieved_nodeId': '',\n",
       " 'isbn10_ref1_retrieved_val': '2022-08-21',\n",
       " 'isbn10_ref1_retrieved_prec': '',\n",
       " 'isbn13_uuid': '',\n",
       " 'isbn13': '978-1-5416-4497-7',\n",
       " 'isbn13_ref1_hash': '',\n",
       " 'isbn13_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'isbn13_ref1_retrieved_nodeId': '',\n",
       " 'isbn13_ref1_retrieved_val': '2022-08-21',\n",
       " 'isbn13_ref1_retrieved_prec': '',\n",
       " 'publisher_uuid': '',\n",
       " 'publisher': 'Q1479937',\n",
       " 'publisher_ref1_hash': '',\n",
       " 'publisher_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'publisher_ref1_retrieved_nodeId': '',\n",
       " 'publisher_ref1_retrieved_val': '2022-08-21',\n",
       " 'publisher_ref1_retrieved_prec': '',\n",
       " 'place_of_publication_uuid': '',\n",
       " 'place_of_publication': 'Q173813',\n",
       " 'place_of_publication_ref1_hash': '',\n",
       " 'place_of_publication_ref1_referenceUrl': 'http://doi.org/10.1353/JBL.2013.0032',\n",
       " 'place_of_publication_ref1_retrieved_nodeId': '',\n",
       " 'place_of_publication_ref1_retrieved_val': '2022-08-21',\n",
       " 'place_of_publication_ref1_retrieved_prec': ''}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict = extract_metadata(config, work_data)\n",
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(config):\n",
    "    out_dict = {'qid': ''}\n",
    "    \n",
    "    for field in out_fields_labels:   \n",
    "        #print(field, crossref_results[field])\n",
    "        out_dict[field] = crossref_results[field]\n",
    "    #print()\n",
    "    for field in out_fields_noref:   \n",
    "        #print(field, crossref_results[field])\n",
    "        out_dict[field + '_uuid'] = ''\n",
    "        out_dict[field] = crossref_results[field]\n",
    "    #print()\n",
    "    \n",
    "    # Fields with a retrieved date, but reference URL not needed\n",
    "    for field in out_fields_no_url:\n",
    "        #print(field, crossref_results[field])\n",
    "        out_dict[field + '_uuid'] = ''\n",
    "        if field == 'published':\n",
    "            out_dict[field + '_nodeId'] = ''\n",
    "            out_dict[field + '_val'] = crossref_results[field]\n",
    "            out_dict[field + '_prec'] = ''\n",
    "        else:\n",
    "            out_dict[field] = crossref_results[field]\n",
    "        # Only add a reference if there is a value for that field\n",
    "        if crossref_results[field] == '':\n",
    "            out_dict[field + '_ref1_hash'] = ''\n",
    "            out_dict[field + '_ref1_retrieved_nodeId'] = ''\n",
    "            out_dict[field + '_ref1_retrieved_val'] = ''\n",
    "            out_dict[field + '_ref1_retrieved_prec'] = ''\n",
    "        else:\n",
    "            out_dict[field + '_ref1_hash'] = ''\n",
    "            out_dict[field + '_ref1_retrieved_nodeId'] = ''\n",
    "            out_dict[field + '_ref1_retrieved_val'] = today\n",
    "            out_dict[field + '_ref1_retrieved_prec'] = ''\n",
    "    #print()\n",
    "    \n",
    "    # Fields with both reference URLs and retrieved dates\n",
    "    for field in out_fields_ref:\n",
    "        #print(field, crossref_results[field])\n",
    "        out_dict[field + '_uuid'] = ''\n",
    "        if field == 'published':\n",
    "            out_dict[field + '_nodeId'] = ''\n",
    "            out_dict[field + '_val'] = crossref_results[field]\n",
    "            out_dict[field + '_prec'] = ''\n",
    "        else:\n",
    "            out_dict[field] = crossref_results[field]\n",
    "        # Only add a reference if there is a value for that field\n",
    "        if crossref_results[field] == '':\n",
    "            out_dict[field + '_ref1_hash'] = ''\n",
    "            out_dict[field + '_ref1_referenceUrl'] = ''\n",
    "            out_dict[field + '_ref1_retrieved_nodeId'] = ''\n",
    "            out_dict[field + '_ref1_retrieved_val'] = ''\n",
    "            out_dict[field + '_ref1_retrieved_prec'] = ''\n",
    "        else:\n",
    "            out_dict[field + '_ref1_hash'] = ''\n",
    "            out_dict[field + '_ref1_referenceUrl'] = handle\n",
    "            out_dict[field + '_ref1_retrieved_nodeId'] = ''\n",
    "            out_dict[field + '_ref1_retrieved_val'] = today\n",
    "            out_dict[field + '_ref1_retrieved_prec'] = ''\n",
    "    return(out_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
